@inproceedings{StyleGAN-T,
  title={StyleGAN-T: Unlocking the Power of GANs for Fast Large-Scale Text-to-Image Synthesis}, 
  author={Axel Sauer and Tero Karras and Samuli Laine and Andreas Geiger and Timo Aila},
  booktitle={ICML},
  year={2023}
}
@inproceedings{DINO,
      title={Emerging Properties in Self-Supervised Vision Transformers}, 
      author={Mathilde Caron and Hugo Touvron and Ishan Misra and Hervé Jégou and Julien Mairal and Piotr Bojanowski and Armand Joulin},
      booktitle={ICCV},
      year={2021}
}
@misc{flux,
    author={Black Forest Labs},
    title={FLUX},
    year={2024},
    howpublished={\url{https://github.com/black-forest-labs/flux}},
}
@inproceedings{VQGAN,
      title={Taming Transformers for High-Resolution Image Synthesis}, 
      author={Patrick Esser and Robin Rombach and Björn Ommer},
      year={2021},
      booktitle={CVPR},
}

@inproceedings{DiffAug,
  title={Differentiable Augmentation for Data-Efficient GAN Training}, 
  author={Shengyu Zhao and Zhijian Liu and Ji Lin and Jun-Yan Zhu and Song Han},
  booktitle={NeurIPS},
  year={2020}
}
@inproceedings{SD3,
      title={Scaling Rectified Flow Transformers for High-Resolution Image Synthesis}, 
      author={Patrick Esser and Sumith Kulal and Andreas Blattmann and Rahim Entezari and Jonas Müller and Harry Saini and Yam Levi and Dominik Lorenz and Axel Sauer and Frederic Boesel and Dustin Podell and Tim Dockhorn and Zion English and Kyle Lacey and Alex Goodwin and Yannik Marek and Robin Rombach},
      year={2024},
      booktitle={ICML},

}

@inproceedings{LDM,
  title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
  author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},
  booktitle={CVPR},
  year={2022}
}
@misc{MassiveActivations,
      title={Massive Activations in Large Language Models}, 
      author={Mingjie Sun and Xinlei Chen and J. Zico Kolter and Zhuang Liu},
      year={2024},
      eprint={2402.17762},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.17762}, 
}

@inproceedings{lgt,
  title={Reconstruction vs. Generation: Taming Optimization Dilemma in Latent Diffusion Models}, 
  author={Jingfeng Yao and Bin Yang and Xinggang Wang},
  booktitle={CVPR},
  year={2025}
}

@misc{GEmbed,
      title={Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains}, 
      author={Matthew Tancik and Pratul P. Srinivasan and Ben Mildenhall and Sara Fridovich-Keil and Nithin Raghavan and Utkarsh Singhal and Ravi Ramamoorthi and Jonathan T. Barron and Ren Ng},
      year={2020},
      eprint={2006.10739},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2006.10739}, 
}

@misc{CFG,
      title={Classifier-Free Diffusion Guidance}, 
      author={Jonathan Ho and Tim Salimans},
      year={2022},
      eprint={2207.12598},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@inproceedings{AG,
  title={Guiding a Diffusion Model with a Bad Version of Itself}, 
  author={Tero Karras and Miika Aittala and Tuomas Kynkäänniemi and Jaakko Lehtinen and Timo Aila and Samuli Laine},
  booktitle={NeurIPS},
  year={2025}
}

@inproceedings{CFGinterval,
  title={Applying Guidance in a Limited Interval Improves Sample and Distribution Quality in Diffusion Models}, 
  author={Tuomas Kynkäänniemi and Miika Aittala and Tero Karras and Samuli Laine and Timo Aila and Jaakko Lehtinen},
  booktitle={NeurIPS},
  year={2024}
}

@inproceedings{maskgit,
  title={Maskgit: Masked generative image transformer},
  author={Chang, Huiwen and Zhang, Han and Jiang, Lu and Liu, Ce and Freeman, William T},
  booktitle={CVPR},
  pages={11315--11325},
  year={2022}
}

@article{llama,
  title={Autoregressive model beats diffusion: Llama for scalable image generation},
  author={Sun, Peize and Jiang, Yi and Chen, Shoufa and Zhang, Shilong and Peng, Bingyue and Luo, Ping and Yuan, Zehuan},
  journal={arXiv preprint arXiv:2406.06525},
  year={2024}
}

@inproceedings{magvit,
  title={Language Model Beats Diffusion--Tokenizer is Key to Visual Generation},
  author={Yu, Lijun and Lezama, Jos{\'e} and Gundavarapu, Nitesh B and Versari, Luca and Sohn, Kihyuk and Minnen, David and Cheng, Yong and Birodkar, Vighnesh and Gupta, Agrim and Gu, Xiuye and others},
  booktitle={ICLR},
  year={2024}
}

@inproceedings{mar,
  title={Autoregressive image generation without vector quantization},
  author={Li, Tianhong and Tian, Yonglong and Li, He and Deng, Mingyang and He, Kaiming},
  booktitle={NeurIPS},
  year={2024}
}

@article{MDTv2,
  title={Mdtv2: Masked diffusion transformer is a strong image synthesizer},
  author={Gao, Shanghua and Zhou, Pan and Cheng, Ming-Ming and Yan, Shuicheng},
  journal={arXiv preprint arXiv:2303.14389},
  year={2023}
}

@inproceedings{MDT,
  title={Masked diffusion transformer is a strong image synthesizer},
  author={Gao, Shanghua and Zhou, Pan and Cheng, Ming-Ming and Yan, Shuicheng},
  booktitle={ICCV},
  year={2023}
}

@inproceedings{repa-e,
  title={REPA-E: Unlocking VAE for End-to-End Tuning with Latent Diffusion Transformers},
  author={Leng, Xingjian and Singh, Jaskirat and Hou, Yunzhong and Xing, Zhenchang and Xie, Saining and Zheng, Liang},
  booktitle={ICCV},
  year={2025}
}
@inproceedings{fasterdit,
  title={Fasterdit: Towards faster diffusion transformers training without architecture modification},
  author={Yao, Jingfeng and Wang, Cheng and Liu, Wenyu and Wang, Xinggang},
  booktitle={NeurIPS},
  year={2024}
} 

@inproceedings{sit,
  title={Sit: Exploring flow and diffusion-based generative models with scalable interpolant transformers},
  author={Ma, Nanye and Goldstein, Mark and Albergo, Michael S and Boffi, Nicholas M and Vanden-Eijnden, Eric and Xie, Saining},
  booktitle={ECCV},
  year={2024}
}

@article{maskdit,
  title={Fast training of diffusion models with masked transformers},
  author={Zheng, Hongkai and Nie, Weili and Vahdat, Arash and Anandkumar, Anima},
  journal={TMLR},
  year={2023}
}
@inproceedings{repa,
  title={Representation Alignment for Generation: Training Diffusion Transformers Is Easier Than You Think},
  author={Yu, Sihyun and Kwak, Sangkyung and Jang, Huiwon and Jeong, Jongheon and Huang, Jonathan and Shin, Jinwoo and Xie, Saining},
  booktitle={ICLR},
  year={2025}
}
@inproceedings{VAR,
  title={Visual autoregressive modeling: Scalable image generation via next-scale prediction},
  author={Tian, Keyu and Jiang, Yi and Yuan, Zehuan and Peng, Bingyue and Wang, Liwei},
  booktitle={NeurIPS},
  year={2024}
}

@inproceedings{dit,
  title={Scalable diffusion models with transformers},
  author={Peebles, William and Xie, Saining},
  booktitle={ICCV},
  year={2023}
}
@inproceedings{magvitv2,
  title={Language Model Beats Diffusion--Tokenizer is Key to Visual Generation},
  author={Yu, Lijun and Lezama, Jos{\'e} and Gundavarapu, Nitesh B and Versari, Luca and Sohn, Kihyuk and Minnen, David and Cheng, Yong and Birodkar, Vighnesh and Gupta, Agrim and Gu, Xiuye and others},
  booktitle={ICLR},
  year={2024}
}

@misc{siglip2,
      title={SigLIP 2: Multilingual Vision-Language Encoders with Improved Semantic Understanding, Localization, and Dense Features}, 
      author={Michael Tschannen and Alexey Gritsenko and Xiao Wang and Muhammad Ferjad Naeem and Ibrahim Alabdulmohsin and Nikhil Parthasarathy and Talfan Evans and Lucas Beyer and Ye Xia and Basil Mustafa and Olivier Hénaff and Jeremiah Harmsen and Andreas Steiner and Xiaohua Zhai},
      year={2025},
      eprint={2502.14786},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
}


@inproceedings{MAE,
      title={Masked Autoencoders Are Scalable Vision Learners}, 
      author={Kaiming He and Xinlei Chen and Saining Xie and Yanghao Li and Piotr Dollár and Ross Girshick},
      year={2021},
      booktitle={CVPR}
}

@article{Dinov2,
  title={Dinov2: Learning robust visual features without supervision},
  author={Oquab, Maxime and Darcet, Timoth{\'e}e and Moutakanni, Th{\'e}o and Vo, Huy and Szafraniec, Marc and Khalidov, Vasil and Fernandez, Pierre and Haziza, Daniel and Massa, Francisco and El-Nouby, Alaaeldin and others},
  journal={TMLR},
  year={2023}
}

@inproceedings{Dinov2wReg,
      title={Vision Transformers Need Registers}, 
      author={Timothée Darcet and Maxime Oquab and Julien Mairal and Piotr Bojanowski},
      year={2025},
      booktitle={ICLR}
}

@misc{ddt,
      title={DDT: Decoupled Diffusion Transformer}, 
      author={Shuai Wang and Zhi Tian and Weilin Huang and Limin Wang},
      year={2025},
      eprint={2504.05741},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
}

@inproceedings{ImprovDiffus,
  title={Improving the Diffusability of Autoencoders}, 
  author={Ivan Skorokhodov and Sharath Girish and Benran Hu and Willi Menapace and Yanyu Li and Rameen Abdal and Sergey Tulyakov and Aliaksandr Siarohin},
  booktitle={ICML},
  year={2025}
}

@misc{ViTok,
      title={Learnings from Scaling Visual Tokenizers for Reconstruction and Generation}, 
      author={Philippe Hansen-Estruch and David Yan and Ching-Yao Chung and Orr Zohar and Jialiang Wang and Tingbo Hou and Tao Xu and Sriram Vishwanath and Peter Vajda and Xinlei Chen},
      year={2025},
      eprint={2501.09755},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2501.09755}, 
}

@misc{sCM,
      title={Simplifying, Stabilizing and Scaling Continuous-Time Consistency Models}, 
      author={Cheng Lu and Yang Song},
      year={2025},
      eprint={2410.11081},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2410.11081}, 
}

@misc{flashattn,
      title={FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness}, 
      author={Tri Dao and Daniel Y. Fu and Stefano Ermon and Atri Rudra and Christopher Ré},
      year={2022},
      eprint={2205.14135},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2205.14135}, 
}

@article{vaeprobe,
  title={Harmonizing visual representations for unified multimodal understanding and generation},
  author={Wu, Size and Zhang, Wenwei and Xu, Lumin and Jin, Sheng and Wu, Zhonghua and Tao, Qingyi and Liu, Wentao and Li, Wei and Loy, Chen Change},
  journal={arXiv preprint arXiv:2503.21979},
  year={2025}
}

@inproceedings{eqvae,
  title={Eq-vae: Equivariance regularized latent space for improved generative image modeling},
  author={Kouzelis, Theodoros and Kakogeorgiou, Ioannis and Gidaris, Spyros and Komodakis, Nikos},
  booktitle={ICML},
  year={2025}
}

@article{imagenet,
  title={Imagenet large scale visual recognition challenge},
  author={Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
  journal={International journal of computer vision},
  volume={115},
  number={3},
  pages={211--252},
  year={2015},
  publisher={Springer}
}

@inproceedings{score_sde,
  title={Score-Based Generative Modeling through Stochastic Differential Equations}, 
  author={Yang Song and Jascha Sohl-Dickstein and Diederik P. Kingma and Abhishek Kumar and Stefano Ermon and Ben Poole},
  booktitle={ICLR},
  year={2021}
}
@inproceedings{fid,
  title={{GANs} Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium},
  author={Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
  booktitle={NeurIPS},
  year={2017}
}

@inproceedings{sfid,
  title={Generating Images with Sparse Representations},
  author={Nash, Charlie and Menick, Jacob and Dieleman, Sander and Battaglia, Peter W},
  booktitle={ICML},
  year={2021}
}

@inproceedings{is,
  title={Improved Techniques for Training {GANs}},
  author={Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi},
  booktitle={NeurIPS},
  year={2016}
}

@inproceedings{prec_and_rec,
  title={Improved Precision and Recall Metric for Assessing Generative Models},
  author={Kynk{\"a}{\"a}nniemi, Tuomas and Karras, Tero and Laine, Samuli and Lehtinen, Jaakko and Aila, Timo},
  booktitle={NeurIPS},
  year={2019}
}

@inproceedings{inceptionv3,
  title={Rethinking the {Inception} Architecture for Computer Vision},
  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  booktitle={CVPR},
  year={2016}
}

@inproceedings{adm,
  title={Diffusion models beat {GANs} on image synthesis},
  author={Dhariwal, Prafulla and Nichol, Alexander},
  booktitle={NeurIPS},
  year={2021}
}

@inproceedings{vdm++,
  title={Understanding Diffusion Objectives as the {ELBO} with Simple Data Augmentation},
  author={Kingma, Diederik and Gao, Ruiqi},
  booktitle={NeurIPS},
  year={2024}
}

@inproceedings{simplediffusion,
  title={Simple Diffusion: End-to-End Diffusion for High Resolution Images},
  author={Hoogeboom, Emiel and Heek, Jonathan and Salimans, Tim},
  booktitle={ICML},
  year={2023},
}

@article{cdm,
  title={Cascaded Diffusion Models for high fidelity image generation},
  author={Ho, Jonathan and Saharia, Chitwan and Chan, William and Fleet, David J and Norouzi, Mohammad and Salimans, Tim},
  journal={Journal of Machine Learning Research},
  volume={23},
  number={47},
  pages={1--33},
  year={2022}
}

@inproceedings{uvit,
  title={All are Worth Words: A {ViT} Backbone for Diffusion Models},
  author={Bao, Fan and Nie, Shen and Xue, Kaiwen and Cao, Yue and Li, Chongxuan and Su, Hang and Zhu, Jun},
  booktitle={CVPR},
  year={2023}
}
@inproceedings{diffit,
  title={{DiffiT}: Diffusion Vision Transformers for Image Generation},
  author={Hatamizadeh, Ali and Song, Jiaming and Liu, Guilin and Kautz, Jan and Vahdat, Arash},
  booktitle={ECCV},
  year={2024}
}


@inproceedings{sddit,
  title={{SD-DiT}: Unleashing the Power of Self-Supervised Discrimination in Diffusion Transformer},
  author={Zhu, Rui and Pan, Yingwei and Li, Yehao and Yao, Ting and Sun, Zhenglong and Mei, Tao and Chen, Chang Wen},
  booktitle={CVPR},
  year={2024}
}

@inproceedings{progressivegan,
  title={Progressive Growing of {GANs} for Improved Quality, Stability, and Variation},
  author={Karras, Tero and Aila, Timo and Laine, Samuli and Lehtinen, Jaakko},
  booktitle={ICLR},
  year={2018}
}

@inproceedings{maetok,
      title={Masked Autoencoders Are Effective Tokenizers for Diffusion Models}, 
      author={Hao Chen and Yujin Han and Fangyi Chen and Xiang Li and Yidong Wang and Jindong Wang and Ze Wang and Zicheng Liu and Difan Zou and Bhiksha Raj},
      year={2025},
      booktitle={ICML},
}

@misc{dcae1p5,
      title={DC-AE 1.5: Accelerating Diffusion Model Convergence with Structured Latent Space}, 
      author={Junyu Chen and Dongyun Zou and Wenkun He and Junsong Chen and Enze Xie and Song Han and Han Cai},
      year={2025},
      eprint={2508.00413},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
}

@misc{ldetok,
      title={Latent Denoising Makes Good Visual Tokenizers}, 
      author={Jiawei Yang and Tianhong Li and Lijie Fan and Yonglong Tian and Yue Wang},
      year={2025},
      eprint={2507.15856},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
}

@inproceedings{titok,
  title={An Image is Worth 32 Tokens for Reconstruction and Generation}, 
  author={Qihang Yu and Mark Weber and Xueqing Deng and Xiaohui Shen and Daniel Cremers and Liang-Chieh Chen},
  booktitle={NeurIPS},
  year={2024}
}
@inproceedings{dcae,
      title={Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models}, 
      author={Junyu Chen and Han Cai and Junsong Chen and Enze Xie and Shang Yang and Haotian Tang and Muyang Li and Yao Lu and Song Han},
      year={2025},
     booktitle={ICLR},
}
@misc{pgv3,
      title={Playground v3: Improving Text-to-Image Alignment with Deep-Fusion Large Language Models}, 
      author={Bingchen Liu and Ehsan Akhgari and Alexander Visheratin and Aleks Kamko and Linmiao Xu and Shivam Shrirao and Chase Lambert and Joao Souza and Suhail Doshi and Daiqing Li},
      year={2024},
      eprint={2409.10695},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
}


@article{moco,
  title={Momentum contrast for unsupervised visual representation learning. arXiv e-prints, art},
  author={He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  journal={arXiv preprint arXiv:1911.05722},
  volume={2},
  year={2019}
}

@inproceedings{dinov1,
  title={Emerging properties in self-supervised vision transformers},
  author={Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J{\'e}gou, Herv{\'e} and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  booktitle={ICCV},
  year={2021}
}
@inproceedings{simclr,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={ICML},
  year={2020},
}

@misc{reg,
      title={Representation Entanglement for Generation:Training Diffusion Transformers Is Much Easier Than You Think}, 
      author={Ge Wu and Shen Zhang and Ruijing Shi and Shanghua Gao and Zhenyuan Chen and Lei Wang and Zhaowei Chen and Hongcheng Gao and Yao Tang and Jian Yang and Ming-Ming Cheng and Xiang Li},
      year={2025},
      eprint={2507.01467},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
}

@inproceedings{redi,
  title={Boosting Generative Image Modeling via Joint Image-Feature Synthesis}, 
  author={Theodoros Kouzelis and Efstathios Karypidis and Ioannis Kakogeorgiou and Spyros Gidaris and Nikos Komodakis},
  booktitle={NeurIPS},
  year={2025}
}
@inproceedings{VAE,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  booktitle={ICLR},
  year={2014}
}

@inproceedings{DAE,
  title={Extracting and composing robust features with denoising autoencoders},
  author={Vincent, Pascal and Larochelle, Hugo and Bengio, Yoshua and Manzagol, Pierre-Antoine},
  booktitle={ICML},
  year={2008}
}

@misc{unilip,
      title={UniLiP: Adapting CLIP for Unified Multimodal Understanding, Generation and Editing}, 
      author={Hao Tang and Chenwei Xie and Xiaoyi Bao and Tingyu Weng and Pandeng Li and Yun Zheng and Liwei Wang},
      year={2025},
      eprint={2507.23278},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
}

@article{stochastic,
  title={Stochastic interpolants: A unifying framework for flows and diffusions},
  author={Albergo, Michael S and Boffi, Nicholas M and Vanden-Eijnden, Eric},
  journal={arXiv preprint arXiv:2303.08797},
  year={2023}
}

@inproceedings{edm,
  title={Elucidating the design space of diffusion-based generative models},
  author={Karras, Tero and Aittala, Miika and Aila, Timo and Laine, Samuli},
  booktitle={NeurIPS},
  year={2022}
}

@inproceedings{ddpm,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  booktitle={NeurIPS},
  year={2020}
}

@inproceedings{fm,
  title={Flow matching for generative modeling},
  author={Lipman, Yaron and Chen, Ricky TQ and Ben-Hamu, Heli and Nickel, Maximilian and Le, Matt},
  booktitle={ICLR},
  year={2023}
}
@inproceedings{rf,
  title={Flow straight and fast: Learning to generate and transfer data with rectified flow},
  author={Liu, Xingchao and Gong, Chengyue and Liu, Qiang},
  booktitle={ICLR},
  year={2023}
}

@article{sbdm,
  title={Score-based generative modeling through stochastic differential equations},
  author={Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
  journal={arXiv preprint arXiv:2011.13456},
  year={2020}
}

@misc{InternViT,
      title={InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models}, 
      author={Jinguo Zhu and Weiyun Wang and Zhe Chen and Zhaoyang Liu and Shenglong Ye and Lixin Gu and Hao Tian and Yuchen Duan and Weijie Su and Jie Shao and Zhangwei Gao and Erfei Cui and Xuehui Wang and Yue Cao and Yangzhou Liu and Xingguang Wei and Hongjie Zhang and Haomin Wang and Weiye Xu and Hao Li and Jiahao Wang and Nianchen Deng and Songze Li and Yinan He and Tan Jiang and Jiapeng Luo and Yi Wang and Conghui He and Botian Shi and Xingcheng Zhang and Wenqi Shao and Junjun He and Yingtong Xiong and Wenwen Qu and Peng Sun and Penglong Jiao and Han Lv and Lijun Wu and Kaipeng Zhang and Huipeng Deng and Jiaye Ge and Kai Chen and Limin Wang and Min Dou and Lewei Lu and Xizhou Zhu and Tong Lu and Dahua Lin and Yu Qiao and Jifeng Dai and Wenhai Wang},
      year={2025},
      eprint={2504.10479},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
}

@misc{blip3o,
      title={BLIP3-o: A Family of Fully Open Unified Multimodal Models-Architecture, Training and Dataset}, 
      author={Jiuhai Chen and Zhiyang Xu and Xichen Pan and Yushi Hu and Can Qin and Tom Goldstein and Lifu Huang and Tianyi Zhou and Saining Xie and Silvio Savarese and Le Xue and Caiming Xiong and Ran Xu},
      year={2025},
      eprint={2505.09568},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
}

@misc{metaquery,
      title={Transfer between Modalities with MetaQueries}, 
      author={Xichen Pan and Satya Narayan Shukla and Aashu Singh and Zhuokai Zhao and Shlok Kumar Mishra and Jialiang Wang and Zhiyang Xu and Jiuhai Chen and Kunpeng Li and Felix Juefei-Xu and Ji Hou and Saining Xie},
      year={2025},
      eprint={2504.06256},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
}

@inproceedings{metamorph,
  title={MetaMorph: Multimodal Understanding and Generation via Instruction Tuning}, 
  author={Shengbang Tong and David Fan and Jiachen Zhu and Yunyang Xiong and Xinlei Chen and Koustuv Sinha and Michael Rabbat and Yann LeCun and Saining Xie and Zhuang Liu},
  booktitle={ICCV},
  year={2025}
}

@inproceedings{emu2,
  title={Generative Multimodal Models are In-Context Learners}, 
  author={Quan Sun and Yufeng Cui and Xiaosong Zhang and Fan Zhang and Qiying Yu and Zhengxiong Luo and Yueze Wang and Yongming Rao and Jingjing Liu and Tiejun Huang and Xinlong Wang},
  booktitle={CVPR},
  year={2024}
}

@inproceedings{vqvae2,
  title={Generating Diverse High-Fidelity Images with VQ-VAE-2}, 
  author={Ali Razavi and Aaron van den Oord and Oriol Vinyals},
  booktitle={NeurIPS},
  year={2019}
}
@inproceedings{iddpm,
  title={Improved Denoising Diffusion Probabilistic Models}, 
  author={Alex Nichol and Prafulla Dhariwal},
  booktitle={ICML},
  year={2021}
}

@misc{vqdiffusion,
      title={Vector Quantized Diffusion Model for Text-to-Image Synthesis}, 
      author={Shuyang Gu and Dong Chen and Jianmin Bao and Fang Wen and Bo Zhang and Dongdong Chen and Lu Yuan and Baining Guo},
      year={2022},
      eprint={2111.14822},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2111.14822}, 
}

@article{abuduweili2024enhancing,
  title={Enhancing Sample Generation of Diffusion Models using Noise Level Correction},
  author={Abuduweili, Abulikemu and Yuan, Chenyang and Liu, Changliu and Permenter, Frank},
  journal={TMLR},
  year={2024}
}

@inproceedings{dinh2016density,
  title={Density estimation using real nvp},
  author={Dinh, Laurent and Sohl-Dickstein, Jascha and Bengio, Samy},
  booktitle={ICLR},
  year={2017}
}

@inproceedings{ho2019flow++,
  title={Flow++: Improving flow-based generative models with variational dequantization and architecture design},
  author={Ho, Jonathan and Chen, Xi and Srinivas, Aravind and Duan, Yan and Abbeel, Pieter},
  booktitle={ICML},
  year={2019},
}

@inproceedings{zhai2024normalizing,
  title={Normalizing flows are capable generative models},
  author={Zhai, Shuangfei and Zhang, Ruixiang and Nakkiran, Preetum and Berthelot, David and Gu, Jiatao and Zheng, Huangjie and Chen, Tianrong and Bautista, Miguel Angel and Jaitly, Navdeep and Susskind, Josh},
  booktitle={ICML},
  year={2025}
}
@inproceedings{teng2023relay,
  title={Relay diffusion: Unifying diffusion process across resolutions for image synthesis},
  author={Teng, Jiayan and Zheng, Wendi and Ding, Ming and Hong, Wenyi and Wangni, Jianqiao and Yang, Zhuoyi and Tang, Jie},
  booktitle={ICLR},
  year={2023}
}
@article{chen2023importance,
  title={On the importance of noise scheduling for diffusion models},
  author={Chen, Ting},
  journal={arXiv preprint arXiv:2301.10972},
  year={2023}
}

@inproceedings{rin,
  title={Scalable adaptive computation for iterative generation},
  author={Jabri, Allan and Fleet, David and Chen, Ting},
  booktitle={ICML},
  year={2023}
}

@inproceedings{sid2,
  title={Simpler diffusion (sid2): 1.5 fid on imagenet512 with pixel-space diffusion},
  author={Hoogeboom, Emiel and Mensink, Thomas and Heek, Jonathan and Lamerigts, Kay and Gao, Ruiqi and Salimans, Tim},
  booktitle={CVPR},
  year={2025}
}

@article{pixelflow,
  title={PixelFlow: Pixel-Space Generative Models with Flow},
  author={Chen, Shoufa and Ge, Chongjian and Zhang, Shilong and Sun, Peize and Luo, Ping},
  journal={arXiv preprint arXiv:2504.07963},
  year={2025}
}

@article{pixnerd,
  title={PixNerd: Pixel Neural Field Diffusion},
  author={Wang, Shuai and Gao, Ziteng and Zhu, Chenhui and Huang, Weilin and Wang, Limin},
  journal={arXiv preprint arXiv:2507.23268},
  year={2025}
}

@inproceedings{vit,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  booktitle={ICLR},
  year={2021}
}

@inproceedings{edm2,
  title={Analyzing and improving the training dynamics of diffusion models},
  author={Karras, Tero and Aittala, Miika and Lehtinen, Jaakko and Hellsten, Janne and Aila, Timo and Laine, Samuli},
  booktitle={CVPR},
  year={2024}
}

@inproceedings{flowdcn,
  title={Flowdcn: Exploring dcn-like architectures for fast image generation with arbitrary resolution},
  author={Wang, Shuai and Li, Zexian and Song, Tianhui and Li, Xubin and Ge, Tiezheng and Zheng, Bo and Wang, Limin},
  booktitle={NeurIPS},
  year={2024}
}
@inproceedings{lpips,
  title={The Unreasonable Effectiveness of Deep Features as a Perceptual Metric}, 
  author={Richard Zhang and Phillip Isola and Alexei A. Efros and Eli Shechtman and Oliver Wang},
  booktitle={CVPR},
  year={2018}
}

@inproceedings{biggan,
      title={Large Scale GAN Training for High Fidelity Natural Image Synthesis}, 
      author={Andrew Brock and Jeff Donahue and Karen Simonyan},
      year={2019},
    booktitle={ICLR},
}

@article{autoencoder,
  title={Reducing the dimensionality of data with neural networks},
  author={Hinton, Geoffrey E and Salakhutdinov, Ruslan R},
  journal={science},
  volume={313},
  number={5786},
  year={2006},
}

@inproceedings{vqvae,
  title={Neural discrete representation learning},
  author={Oord, Aaron van den and Vinyals, Oriol and Kavukcuoglu, Koray},
  booktitle={NeurIPS},
  year={2017}
}

@inproceedings{GAN,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  booktitle={NeurIPS},
  year={2014}
}

@inproceedings{ViT-VQGAN,
  title={Vector-quantized image modeling with improved vqgan},
  author={Yu, Jiahui and Li, Xin and Koh, Jing Yu and Zhang, Han and Pang, Ruoming and Qin, James and Ku, Alexander and Xu, Yuanzhong and Baldridge, Jason and Wu, Yonghui},
  booktitle={ICLR},
  year={2022}
}

@inproceedings{Efficient-VQGAN,
  title={Efficient-VQGAN: Towards High-Resolution Image Generation with Efficient Vision Transformers},
  author={Cao, Shiyue and Yin, Yueqin and Huang, Lianghua and Liu, Yu and Zhao, Xin and Zhao, Deli and Huang, Kaigi},
  booktitle={ICCV},
  year={2023}
}

@inproceedings{rqvae,
  title={Autoregressive image generation using residual quantization},
  author={Lee, Doyup and Kim, Chiheon and Kim, Saehoon and Cho, Minsu and Han, Wook-Shin},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{movq,
  title={Movq: Modulating quantized vectors for high-fidelity image generation},
  author={Zheng, Chuanxia and Vuong, Tung-Long and Cai, Jianfei and Phung, Dinh},
  booktitle={NeurIPS},
  year={2022}
}

@inproceedings{fsq,
    title={Finite Scalar Quantization: {VQ}-{VAE} Made Simple},
    author={Fabian Mentzer and David Minnen and Eirikur Agustsson and Michael Tschannen},
    booktitle={ICLR},
    year={2024},
}


@misc{textok,
      title={Democratizing Text-to-Image Masked Generative Models with Compact Text-Aware One-Dimensional Tokens}, 
      author={Dongwon Kim and Ju He and Qihang Yu and Chenglin Yang and Xiaohui Shen and Suha Kwak and Liang-Chieh Chen},
      year={2025},
      eprint={2501.07730},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2501.07730}, 
}


@inproceedings{fluid,
      title={Fluid: Scaling Autoregressive Text-to-image Generative Models with Continuous Tokens}, 
      author={Lijie Fan and Tianhong Li and Siyang Qin and Yuanzhen Li and Chen Sun and Michael Rubinstein and Deqing Sun and Kaiming He and Yonglong Tian},
      year={2025},
      booktitle={ICLR},
}


@article{ar1,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  volume={1},
  number={2},
  pages={3},
  year={2022}
}


@article{ar2,
  title={Scaling autoregressive models for content-rich text-to-image generation},
  author={Yu, Jiahui and Xu, Yuanzhong and Koh, Jing Yu and Luong, Thang and Baid, Gunjan and Wang, Zirui and Vasudevan, Vijay and Ku, Alexander and Yang, Yinfei and Ayan, Burcu Karagol and others},
  journal={TMLR},
  year={2022},
}

@inproceedings{image-transformer,
  title={Image transformer},
  author={Parmar, Niki and Vaswani, Ashish and Uszkoreit, Jakob and Kaiser, Lukasz and Shazeer, Noam and Ku, Alexander and Tran, Dustin},
  booktitle={ICML},
  year={2018}
}

@inproceedings{gpt-pixel,
  title={Generative pretraining from pixels},
  author={Chen, Mark and Radford, Alec and Child, Rewon and Wu, Jeffrey and Jun, Heewoo and Luan, David and Sutskever, Ilya},
  booktitle={ICML},
  year={2020}
}

@inproceedings{maskgit,
  title={Maskgit: Masked generative image transformer},
  author={Chang, Huiwen and Zhang, Han and Jiang, Lu and Liu, Ce and Freeman, William T},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{mage,
  title={Mage: Masked generative encoder to unify representation learning and image synthesis},
  author={Li, Tianhong and Chang, Huiwen and Mishra, Shlok and Zhang, Han and Katabi, Dina and Krishnan, Dilip},
  booktitle={CVPR},
  year={2023}
}

@article{maskbit,
  title={MaskBit: Embedding-free Image Generation via Bit Tokens},
  author={Weber, Mark and Yu, Lijun and Yu, Qihang and Deng, Xueqing and Shen, Xiaohui and Cremers, Daniel and Chen, Liang-Chieh},
  journal={arXiv preprint arXiv:2409.16211},
  year={2024}
}

@inproceedings{bsq,
  title={Image and Video Tokenization with Binary Spherical Quantization}, 
  author={Yue Zhao and Yuanjun Xiong and Philipp Krähenbühl},
  booktitle={ICLR},
  year={2025}
}
@misc{gigatok,
      title={GigaTok: Scaling Visual Tokenizers to 3 Billion Parameters for Autoregressive Image Generation}, 
      author={Tianwei Xiong and Jun Hao Liew and Zilong Huang and Jiashi Feng and Xihui Liu},
      year={2025},
      eprint={2504.08736},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2504.08736}, 
}

@inproceedings{CRT,
  title={When Worse is Better: Navigating the compression-generation tradeoff in visual tokenization}, 
  author={Vivek Ramanujan and Kushal Tirumala and Armen Aghajanyan and Luke Zettlemoyer and Ali Farhadi},
  booktitle={NeurIPS},
  year={2025}
}

@inproceedings{LARP,
  title={LARP: Tokenizing Videos with a Learned Autoregressive Generative Prior}, 
  author={Hanyu Wang and Saksham Suri and Yixuan Ren and Hao Chen and Abhinav Shrivastava},
  booktitle={ICLR},
  year={2025}
}
@misc{eps-vae,
      title={Epsilon-VAE: Denoising as Visual Decoding}, 
      author={Long Zhao and Sanghyun Woo and Ziyu Wan and Yandong Li and Han Zhang and Boqing Gong and Hartwig Adam and Xuhui Jia and Ting Liu},
      year={2025},
      eprint={2410.04081},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2410.04081}, 
}

@inproceedings{liu2023visual,
    title={Visual Instruction Tuning}, 
    author={Haotian Liu and Chunyuan Li and Qingyang Wu and Yong Jae Lee},
    booktitle={NeurIPS},
    year={2023}
}


@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={CVPR},
  year={2009},
}

@inproceedings{xu2023demystifying,
  title={Demystifying clip data},
  author={Xu, Hu and Xie, Saining and Tan, Xiaoqing Ellen and Huang, Po-Yao and Howes, Russell and Sharma, Vasu and Li, Shang-Wen and Ghosh, Gargi and Zettlemoyer, Luke and Feichtenhofer, Christoph},
  booktitle={ICLR},
  year={2024}
}

@inproceedings{fan2023motion,
    title={Motion-guided masking for spatiotemporal representation learning},
    author={Fan, David and Wang, Jue and Liao, Shuai and Zhu, Yi and Bhat, Vimal and Santos-Villalobos, Hector and MV, Rohith and Li, Xinyu},
    booktitle={ICCV},
    year={2023}
}

@inproceedings{fang2022data,
  title={Data determines distributional robustness in contrastive language image pre-training (clip)},
  author={Fang, Alex and Ilharco, Gabriel and Wortsman, Mitchell and Wan, Yuhao and Shankar, Vaishaal and Dave, Achal and Schmidt, Ludwig},
  booktitle={ICML},
  year={2022},
}

@inproceedings{sun2017revisiting,
  title={Revisiting unreasonable effectiveness of data in deep learning era},
  author={Sun, Chen and Shrivastava, Abhinav and Singh, Saurabh and Gupta, Abhinav},
  booktitle={ICCV},
  year={2017}
}

@article{sutton2019bitter,
  title={The bitter lesson},
  author={Sutton, Richard},
  journal={Incomplete Ideas (blog)},
  year={2019}
}

@article{jose2024dinov2,
  title={DINOv2 Meets Text: A Unified Framework for Image-and Pixel-Level Vision-Language Alignment},
  author={Jose, Cijo and Moutakanni, Th{\'e}o and Kang, Dahyun and Baldassarre, Federico and Darcet, Timoth{\'e}e and Xu, Hu and Li, Daniel and Szafraniec, Marc and Ramamonjisoa, Micha{\"e}l and Oquab, Maxime and others},
  journal={arXiv preprint arXiv:2412.16334},
  year={2024}
}

@inproceedings{zhai2022lit,
  title={Lit: Zero-shot transfer with locked-image text tuning},
  author={Zhai, Xiaohua and Wang, Xiao and Mustafa, Basil and Steiner, Andreas and Keysers, Daniel and Kolesnikov, Alexander and Beyer, Lucas},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={18123--18133},
  year={2022}
}

%%% Peter's citations

@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}

@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}
@article{power2022grokking,
  title={Grokking: Generalization beyond overfitting on small algorithmic datasets},
  author={Power, Alethea and Burda, Yuri and Edwards, Harri and Babuschkin, Igor and Misra, Vedant},
  journal={arXiv preprint arXiv:2201.02177},
  year={2022}
}


@article{wang2023see,
  title={To see is to believe: Prompting gpt-4v for better visual instruction tuning},
  author={Wang, Junke and Meng, Lingchen and Weng, Zejia and He, Bo and Wu, Zuxuan and Jiang, Yu-Gang},
  journal={arXiv preprint arXiv:2311.07574},
  year={2023}
}

@article{zhang2023llavar,
  title={Llavar: Enhanced visual instruction tuning for text-rich image understanding},
  author={Zhang, Yanzhe and Zhang, Ruiyi and Gu, Jiuxiang and Zhou, Yufan and Lipka, Nedim and Yang, Diyi and Sun, Tong},
  journal={arXiv preprint arXiv:2306.17107},
  year={2023}
}
@inproceedings{liu2022convnet,
  title={A convnet for the 2020s},
  author={Liu, Zhuang and Mao, Hanzi and Wu, Chao-Yuan and Feichtenhofer, Christoph and Darrell, Trevor and Xie, Saining},
  booktitle={CVPR},
  year={2022}
}
@inproceedings{masry2022chartqa,
  title={Chartqa: A benchmark for question answering about charts with visual and logical reasoning},
  author={Masry, Ahmed and Long, Do Xuan and Tan, Jia Qing and Joty, Shafiq and Hoque, Enamul},
  booktitle={ACL},
  year={2022}
}
@inproceedings{mathew2021docvqa,
  title={Docvqa: A dataset for vqa on document images},
  author={Mathew, Minesh and Karatzas, Dimosthenis and Jawahar, CV},
  booktitle={WACV},
  year={2021}
}
@inproceedings{kafle2018dvqa,
  title={Dvqa: Understanding data visualizations via question answering},
  author={Kafle, Kushal and Price, Brian and Cohen, Scott and Kanan, Christopher},
  booktitle={CVPR},
  year={2018}
}

@inproceedings{acharya2019tallyqa,
  title={TallyQA: Answering complex counting questions},
  author={Acharya, Manoj and Kafle, Kushal and Kanan, Christopher},
  booktitle={AAAI},
  year={2019}
}
@inproceedings{johnson2017clevr,
  title={Clevr: A diagnostic dataset for compositional language and elementary visual reasoning},
  author={Johnson, Justin and Hariharan, Bharath and Van Der Maaten, Laurens and Fei-Fei, Li and Lawrence Zitnick, C and Girshick, Ross},
  booktitle={CVPR},
  year={2017}
}
@article{tu2023many,
  title={How many unicorns are in this image? a safety evaluation benchmark for vision llms},
  author={Tu, Haoqin and Cui, Chenhang and Wang, Zijun and Zhou, Yiyang and Zhao, Bingchen and Han, Junlin and Zhou, Wangchunshu and Yao, Huaxiu and Xie, Cihang},
  journal={arXiv preprint arXiv:2311.16101},
  year={2023}
}


@inproceedings{gurari2018vizwiz,
  title={Vizwiz grand challenge: Answering visual questions from blind people},
  author={Gurari, Danna and Li, Qing and Stangl, Abigale J and Guo, Anhong and Lin, Chi and Grauman, Kristen and Luo, Jiebo and Bigham, Jeffrey P},
  booktitle={CVPR},
  year={2018}
}
@inproceedings{zhang2023pre,
  title={Pre-trained Language Models Do Not Help Auto-regressive Text-to-Image Generation},
  author={Zhang, Yuhui and McKinzie, Brandon and Gan, Zhe and Shankar, Vaishaal and Toshev, Alexander},
  booktitle={EMNLP},
  year={2023},
}
@article{chen2024allava,
  title={ALLaVA: Harnessing GPT4V-synthesized Data for A Lite Vision-Language Model},
  author={Chen, Guiming Hardy and Chen, Shunian and Zhang, Ruifei and Chen, Junying and Wu, Xiangbo and Zhang, Zhiyi and Chen, Zhihong and Li, Jianquan and Wan, Xiang and Wang, Benyou},
  journal={arXiv preprint arXiv:2402.11684},
  year={2024}
}
@article{lambon2010coherent,
  title={Coherent concepts are computed in the anterior temporal lobes},
  author={Lambon Ralph, Matthew A and Sage, Karen and Jones, Roy W and Mayberry, Emily J},
  journal={Proceedings of the National Academy of Sciences},
  volume={107},
  number={6},
  pages={2717--2722},
  year={2010},
  publisher={National Acad Sciences}
}
@inproceedings{chen2020simple,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={ICML},
  year={2020},
}
@inproceedings{he2019momentum,
  title={Momentum Contrast for Unsupervised Visual Representation Learning. arXiv e-prints, art},
  author={He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  booktitle={CVPR},
  year={2019}
}
@inproceedings{bardes2024revisiting,
  title={Revisiting feature prediction for learning visual representations from video},
  author={Bardes, Adrien and Garrido, Quentin and Ponce, Jean and Chen, Xinlei and Rabbat, Michael and LeCun, Yann and Assran, Mahmoud and Ballas, Nicolas},
  booktitle={TMLR},
  year={2024}
}
@article{hendrycks2016gaussian,
  title={Gaussian error linear units (gelus)},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1606.08415},
  year={2016}
}
@article{zhang2024direct,
  title={Direct Preference Optimization of Video Large Multimodal Models from Language Model Reward},
  author={Zhang, Ruohong and Gui, Liangke and Sun, Zhiqing and Feng, Yihao and Xu, Keyang and Zhang, Yuanhan and Fu, Di and Li, Chunyuan and Hauptmann, Alexander and Bisk, Yonatan and others},
  journal={arXiv preprint arXiv:2404.01258},
  year={2024}
}
@inproceedings{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, I},
  booktitle={ICLR},
  year={2019}
}
@inproceedings{ba2016layer,
  title={Layer normalization},
  author={Ba, Jimmy Lei  and Kiros, Jamie and Geoffrey E. Hinton},
  booktitle={NeurIPS},
  year={2016}
}
@inproceedings{preechakul2022diffusion,
  title={Diffusion autoencoders: Toward a meaningful and decodable representation},
  author={Preechakul, Konpat and Chatthee, Nattanat and Wizadwongsa, Suttisak and Suwajanakorn, Supasorn},
  booktitle={CVPR},
  year={2022}
}
@inproceedings{pan2023kosmos,
  title={Kosmos-g: Generating images in context with multimodal large language models},
  author={Pan, Xichen and Dong, Li and Huang, Shaohan and Peng, Zhiliang and Chen, Wenhu and Wei, Furu},
  booktitle={ICLR},
  year={2024}
}
@inproceedings{koh2024generating,
  title={Generating images with multimodal language models},
  author={Koh, Jing Yu and Fried, Daniel and Salakhutdinov, Russ R},
  booktitle={NeurIPS},
  year={2024}
}
@inproceedings{rajbhandari2020zero,
  title={Zero: Memory optimizations toward training trillion parameter models},
  author={Rajbhandari, Samyam and Rasley, Jeff and Ruwase, Olatunji and He, Yuxiong},
  booktitle={SC20: International Conference for High Performance Computing, Networking, Storage and Analysis},
  pages={1--16},
  year={2020},
  organization={IEEE}
}
@inproceedings{heusel2017gans,
  title={Gans trained by a two time-scale update rule converge to a local nash equilibrium},
  author={Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
  booktitle={NeurIPS},
  year={2017}
}
@article{yue2024mmmu,
  title={Mmmu-pro: A more robust multi-discipline multimodal understanding benchmark},
  author={Yue, Xiang and Zheng, Tianyu and Ni, Yuansheng and Wang, Yubo and Zhang, Kai and Tong, Shengbang and Sun, Yuxuan and Yin, Ming and Yu, Botao and Zhang, Ge and others},
  journal={arXiv preprint arXiv:2409.02813},
  year={2024}
}
@inproceedings{pan2024autonomous,
  title={Autonomous evaluation and refinement of digital agents},
  author={Pan, Jiayi and Zhang, Yichi and Tomlin, Nicholas and Zhou, Yifei and Levine, Sergey and Suhr, Alane},
  booktitle={COLM},
  year={2024}
}
@article{cha2024visually,
  title={Visually Dehallucinative Instruction Generation: Know What You Don't Know},
  author={Cha, Sungguk and Lee, Jusung and Lee, Younghyun and Yang, Cheoljong},
  journal={arXiv preprint arXiv:2402.09717},
  year={2024}
}
@article{si2024design2code,
  title={Design2Code: How Far Are We From Automating Front-End Engineering?},
  author={Si, Chenglei and Zhang, Yanzhe and Yang, Zhengyuan and Liu, Ruibo and Yang, Diyi},
  journal={arXiv preprint arXiv:2403.03163},
  year={2024}
}
@article{li2024multimodal,
  title={Multimodal ArXiv: A Dataset for Improving Scientific Comprehension of Large Vision-Language Models},
  author={Li, Lei and Wang, Yuqi and Xu, Runxin and Wang, Peiyi and Feng, Xiachong and Kong, Lingpeng and Liu, Qi},
  journal={arXiv preprint arXiv:2403.00231},
  year={2024}
}
@article{wang2024measuring,
  title={Measuring Multimodal Mathematical Reasoning with MATH-Vision Dataset},
  author={Wang, Ke and Pan, Junting and Shi, Weikang and Lu, Zimu and Zhan, Mingjie and Li, Hongsheng},
  journal={arXiv preprint arXiv:2402.14804},
  year={2024}
}

@article{wu2023q,
  title={Q-instruct: Improving low-level visual abilities for multi-modality foundation models},
  author={Wu, Haoning and Zhang, Zicheng and Zhang, Erli and Chen, Chaofeng and Liao, Liang and Wang, Annan and Xu, Kaixin and Li, Chunyi and Hou, Jingwen and Zhai, Guangtao and others},
  journal={arXiv preprint arXiv:2311.06783},
  year={2023}
}

@inproceedings{kembhavi2016diagram,
  title={A diagram is worth a dozen images},
  author={Kembhavi, Aniruddha and Salvato, Mike and Kolve, Eric and Seo, Minjoon and Hajishirzi, Hannaneh and Farhadi, Ali},
  booktitle={ECCV},
  year={2016},
}

@misc{laiongpt4v,
  title={laion/gpt4v-dataset},
  author={LAION},
  year={2023},
  url={https://huggingface.co/datasets/laion/gpt4v-dataset}
}

@article{hsiao2022screenqa,
  title={Screenqa: Large-scale question-answer pairs over mobile app screenshots},
  author={Hsiao, Yu-Chung and Zubach, Fedir and Wang, Maria and others},
  journal={arXiv preprint arXiv:2209.08199},
  year={2022}
}

@inproceedings{lu2022learn,
  title={Learn to explain: Multimodal reasoning via thought chains for science question answering},
  author={Lu, Pan and Mishra, Swaroop and Xia, Tanglin and Qiu, Liang and Chang, Kai-Wei and Zhu, Song-Chun and Tafjord, Oyvind and Clark, Peter and Kalyan, Ashwin},
  booktitle={NeurIPS},
  year={2022}
}
@article{gao2023g,
  title={G-llava: Solving geometric problem with multi-modal large language model},
  author={Gao, Jiahui and Pi, Renjie and Zhang, Jipeng and Ye, Jiacheng and Zhong, Wanjun and Wang, Yufei and Hong, Lanqing and Han, Jianhua and Xu, Hang and Li, Zhenguo and others},
  journal={arXiv preprint arXiv:2312.11370},
  year={2023}
}
@inproceedings{kim2021donut,
  title={Donut: Document understanding transformer without ocr},
  author={Kim, Geewook and Hong, Teakgyu and Yim, Moonbin and Park, Jinyoung and Yim, Jinyeong and Hwang, Wonseok and Yun, Sangdoo and Han, Dongyoon and Park, Seunghyun},
  booktitle={ECCV},
  year={2022}
}
@article{laurenccon2024unlocking,
  title={Unlocking the conversion of Web Screenshots into HTML Code with the WebSight Dataset},
  author={Lauren{\c{c}}on, Hugo and Tronchon, L{\'e}o and Sanh, Victor},
  journal={arXiv preprint arXiv:2403.09029},
  year={2024}
}
@inproceedings{belouadi2023automatikz,
  title={Automatikz: Text-guided synthesis of scientific vector graphics with tikz},
  author={Belouadi, Jonas and Lauscher, Anne and Eger, Steffen},
  booktitle={ICLR},
  year={2024}
}
@article{alawwad2024enhancing,
  title={Enhancing Textbook Question Answering Task with Large Language Models and Retrieval Augmented Generation},
  author={Alawwad, Hessa Abdulrahman and Alhothali, Areej and Naseem, Usman and Alkhathlan, Ali and Jamal, Amani},
  journal={arXiv preprint arXiv:2402.05128},
  year={2024}
}
@inproceedings{lu2021inter,
  title={Inter-GPS: Interpretable geometry problem solving with formal language and symbolic reasoning},
  author={Lu, Pan and Gong, Ran and Jiang, Shibiao and Qiu, Liang and Huang, Siyuan and Liang, Xiaodan and Zhu, Song-Chun},
  booktitle={ACL},
  year={2021}
}
@inproceedings{zhang2019raven,
  title={Raven: A dataset for relational and analogical visual reasoning},
  author={Zhang, Chi and Gao, Feng and Jia, Baoxiong and Zhu, Yixin and Zhu, Song-Chun},
  booktitle={CVPR},
  year={2019}
}
@inproceedings{lu2021iconqa,
  title={Iconqa: A new benchmark for abstract diagram understanding and visual language reasoning},
  author={Lu, Pan and Qiu, Liang and Chen, Jiaqi and Xia, Tony and Zhao, Yizhou and Zhang, Wei and Yu, Zhou and Liang, Xiaodan and Zhu, Song-Chun},
  booktitle={NeurIPS},
  year={2021}
}
@inproceedings{kazemi2023geomverse,
  title={Geomverse: A systematic evaluation of large models for geometric reasoning},
  author={Kazemi, Mehran and Alvari, Hamidreza and Anand, Ankit and Wu, Jialin and Chen, Xi and Soricut, Radu},
  journal={arXiv preprint arXiv:2312.12241},
  year={2023}
}
@inproceedings{pasupat2015compositional,
  title={Compositional semantic parsing on semi-structured tables},
  author={Pasupat, Panupong and Liang, Percy},
  booktitle={ACL},
  year={2015}
}
@inproceedings{zhong2017seq2sql,
  title={Seq2sql: Generating structured queries from natural language using reinforcement learning},
  author={Zhong, Victor and Xiong, Caiming and Socher, Richard},
  journal={arXiv preprint arXiv:1709.00103},
  year={2017}
}

@inproceedings{chen2021finqa,
  title={Finqa: A dataset of numerical reasoning over financial data},
  author={Chen, Zhiyu and Chen, Wenhu and Smiley, Charese and Shah, Sameena and Borova, Iana and Langdon, Dylan and Moussa, Reema and Beane, Matt and Huang, Ting-Hao and Routledge, Bryan and others},
  booktitle={EMNLP},
  year={2021}
}

@inproceedings{cheng2021hitab,
  title={HiTab: A hierarchical table dataset for question answering and natural language generation},
  author={Cheng, Zhoujun and Dong, Haoyu and Wang, Zhiruo and Jia, Ran and Guo, Jiaqi and Gao, Yan and Han, Shi and Lou, Jian-Guang and Zhang, Dongmei},
  booktitle={ACL},
  year={2022}
}
@inproceedings{zhu2021tat,
  title={TAT-QA: A question answering benchmark on a hybrid of tabular and textual content in finance},
  author={Zhu, Fengbin and Lei, Wenqiang and Huang, Youcheng and Wang, Chao and Zhang, Shuo and Lv, Jiancheng and Feng, Fuli and Chua, Tat-Seng},
  booktitle={ACL},
  year={2021}
}

@inproceedings{lu2022dynamic,
  title={Dynamic prompt learning via policy gradient for semi-structured mathematical reasoning},
  author={Lu, Pan and Qiu, Liang and Chang, Kai-Wei and Wu, Ying Nian and Zhu, Song-Chun and Rajpurohit, Tanmay and Clark, Peter and Kalyan, Ashwin},
  booktitle={ICLR},
  year={2023},
}
@inproceedings{kantharaj2022chart,
  title={Chart-to-text: A large-scale benchmark for chart summarization},
  author={Kantharaj, Shankar and Leong, Rixie Tiffany Ko and Lin, Xiang and Masry, Ahmed and Thakkar, Megh and Hoque, Enamul and Joty, Shafiq},
  booktitle={ACL},
  year={2022}
}
@article{tang2023vistext,
  title={Vistext: A benchmark for semantically rich chart captioning},
  author={Tang, Benny J and Boggust, Angie and Satyanarayan, Arvind},
  journal={arXiv preprint arXiv:2307.05356},
  year={2023}
}
@inproceedings{biten2022latr,
  title={Latr: Layout-aware transformer for scene-text vqa},
  author={Biten, Ali Furkan and Litman, Ron and Xie, Yusheng and Appalaraju, Srikar and Manmatha, R},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{biten2019scene,
  title={Scene text visual question answering},
  author={Biten, Ali Furkan and Tito, Ruben and Mafla, Andres and Gomez, Lluis and Rusinol, Mar{\c{c}}al and Valveny, Ernest and Jawahar, CV and Karatzas, Dimosthenis},
  booktitle={ICCV},
  year={2019}
}
@inproceedings{kiela2020hateful,
  title={The hateful memes challenge: Detecting hate speech in multimodal memes},
  author={Kiela, Douwe and Firooz, Hamed and Mohan, Aravind and Goswami, Vedanuj and Singh, Amanpreet and Ringshia, Pratik and Testuggine, Davide},
  booktitle={NeurIPS},
  year={2020}
}
@misc{RenderedText,
  title={wendlerc/RenderedText},
  author={Chris Wendler},
  year={2023},
  url={https://huggingface.co/datasets/wendlerc/RenderedText}
}

@inproceedings{zhu2016visual7w,
  title={Visual7w: Grounded question answering in images},
  author={Zhu, Yuke and Groth, Oliver and Bernstein, Michael and Fei-Fei, Li},
  booktitle={CVPR},
  year={2016}
}

@inproceedings{tanaka2021visualmrc,
  title={VisualMRC: Machine Reading Comprehension on Document Images},
  author={Tanaka, Ryota and Nishida, Kyosuke and Yoshida, Sen},
  booktitle={AAAI},
  year={2021}
}

@inproceedings{shridhar2020alfworld,
  title={ALFWorld: Aligning Text and Embodied Environments for Interactive Learning},
  author={Shridhar, Mohit and Yuan, Xingdi and C{\^{o}}t{\'{e}}, Marc{-}Alexandre and Bisk, Yonatan and Trischler, Adam and Hausknecht, Matthew J.},
  booktitle={ICLR},
  year={2021}
}

@inproceedings{pont-tuset2019localizednarratives,
  title={Connecting Vision and Language with Localized Narratives},
  author={Pont{-}Tuset, Jordi and Uijlings, Jasper R. R. and Changpinyo, Soravit and Soricut, Radu and Ferrari, Vittorio},
  booktitle={ECCV},
  year={2020}
}

@article{he2020pathvqa,
  title={PathVQA: 30000+ Questions for Medical Visual Question Answering},
  author={He, Xuehai and Zhang, Yichen and Mou, Luntian and Xing, Eric P. and Xie, Pengtao},
  journal={CoRR},
  volume={abs/2003.10286},
  year={2020}
}

@article{chen2023sharegpt4v,
  title={Sharegpt4v: Improving large multi-modal models with better captions},
  author={Chen, Lin and Li, Jisong and Dong, Xiaoyi and Zhang, Pan and He, Conghui and Wang, Jiaqi and Zhao, Feng and Lin, Dahua},
  journal={arXiv preprint arXiv:2311.12793},
  year={2023}
}

@inproceedings{hudson2019gqa,
      title={GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question Answering}, 
      author={Drew A. Hudson and Christopher D. Manning},
      year={2019},
      booktitle={CVPR},
}

@inproceedings{marino2019okvqa,
      title={OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge}, 
      author={Kenneth Marino and Mohammad Rastegari and Ali Farhadi and Roozbeh Mottaghi},
      booktitle={CVPR},
      year={2019},
}
@inproceedings{vishniakov2023convnet,
  title={ConvNet vs Transformer, Supervised vs CLIP: Beyond ImageNet Accuracy},
  author={Vishniakov, Kirill and Shen, Zhiqiang and Liu, Zhuang},
  booktitle={ICML},
  year={2024}
}
@inproceedings{schwenk2022aokvqa,
      title={A-OKVQA: A Benchmark for Visual Question Answering using World Knowledge}, 
      author={Dustin Schwenk and Apoorv Khandelwal and Christopher Clark and Kenneth Marino and Roozbeh Mottaghi},
      booktitle={ECCV},
      year={2022}
}

@inproceedings{mishra2019OCR,
      title={OCR-VQA: Visual Question Answering by Reading Text in Images},
      authpr={Anand Mishra and Shashank Shekhar and Ajeet Kumar Singh and Anirban Chakraborty},
      year={2019},
      archivePrefix={International Conference on Document Analysis and Recognition},
      primaryClass={cs.CV}
}
@misc{sidorov2020textcaps,
      title={TextCaps: a Dataset for Image Captioning with Reading Comprehension}, 
      author={Oleksii Sidorov and Ronghang Hu and Marcus Rohrbach and Amanpreet Singh},
      year={2020},
      eprint={2003.12462},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{yu2016modeling,
      title={Modeling Context in Referring Expressions}, 
      author={Licheng Yu and Patrick Poirson and Shan Yang and Alexander C. Berg and Tamara L. Berg},
      year={2016},
      eprint={1608.00272},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@article{team2024chameleon,
  title={Chameleon: Mixed-Modal Early-Fusion Foundation Models},
  author={Team, Chameleon},
  journal={arXiv preprint arXiv:2405.09818},
  year={2024}
}
@article{yu2023rlhf,
  title={Rlhf-v: Towards trustworthy mllms via behavior alignment from fine-grained correctional human feedback},
  author={Yu, Tianyu and Yao, Yuan and Zhang, Haoye and He, Taiwen and Han, Yifeng and Cui, Ganqu and Hu, Jinyi and Liu, Zhiyuan and Zheng, Hai-Tao and Sun, Maosong and others},
  journal={arXiv preprint arXiv:2312.00849},
  year={2023}
}
@inproceedings{li2024return,
  title={Return of unconditional generation: A self-supervised representation generation method},
  author={Li, Tianhong and Katabi, Dina and He, Kaiming},
  booktitle={NeurIPS},
  year={2024}
}
@inproceedings{rafailov2024direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
  booktitle={NeurIPS},
  year={2024}
}

@misc{zhu2023starling,
  title={Starling-7b: Improving llm helpfulness \& harmlessness with rlaif},
  author={Zhu, Banghua and Frick, Evan and Wu, Tianhao and Zhu, Hanlin and Jiao, Jiantao},
  year={2023},
  publisher={November}
}

@inproceedings{he2017mask,
  title={Mask r-cnn},
  author={He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={ICCV},
  year={2017}
}

@inproceedings{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  booktitle={NeurIPS},
  year={2022}
}
@article{dong2024rlhf,
  title={Rlhf workflow: From reward modeling to online rlhf},
  author={Dong, Hanze and Xiong, Wei and Pang, Bo and Wang, Haoxiang and Zhao, Han and Zhou, Yingbo and Jiang, Nan and Sahoo, Doyen and Xiong, Caiming and Zhang, Tong},
  journal={arXiv preprint arXiv:2405.07863},
  year={2024}
}
@inproceedings{liu2024decade,
  title={A Decade's Battle on Dataset Bias: Are We There Yet?},
  author={Liu, Zhuang and He, Kaiming},
  booktitle={ICLR},
  year={2025}
}
@inproceedings{woo2023convnext,
  title={Convnext v2: Co-designing and scaling convnets with masked autoencoders},
  author={Woo, Sanghyun and Debnath, Shoubhik and Hu, Ronghang and Chen, Xinlei and Liu, Zhuang and Kweon, In So and Xie, Saining},
  booktitle={CVPR},
  year={2023}
}

@inproceedings{yuksekgonul2022and,
  title={When and why vision-language models behave like bags-of-words, and what to do about it?},
  author={Yuksekgonul, Mert and Bianchi, Federico and Kalluri, Pratyusha and Jurafsky, Dan and Zou, James},
  booktitle={ICLR},
  year={2022}
}
@article{chen2024far,
  title={How far are we to gpt-4v? closing the gap to commercial multimodal models with open-source suites},
  author={Chen, Zhe and Wang, Weiyun and Tian, Hao and Ye, Shenglong and Gao, Zhangwei and Cui, Erfei and Tong, Wenwen and Hu, Kongzhi and Luo, Jiapeng and Ma, Zheng and others},
  journal={arXiv preprint arXiv:2404.16821},
  year={2024}
}

@inproceedings{tong2024mass,
  title={Mass-producing failures of multimodal systems with language models},
  author={Tong, Shengbang and Jones, Erik and Steinhardt, Jacob},
  booktitle={NeurIPS},
  year={2024}
}
@article{krishna2016visual,
      title={Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations}, 
      author={Ranjay Krishna and Yuke Zhu and Oliver Groth and Justin Johnson and Kenji Hata and Joshua Kravitz and Stephanie Chen and Yannis Kalantidis and Li-Jia Li and David A. Shamma and Michael S. Bernstein and Fei-Fei Li},
      journal={IJCV},
      year={2016},
}

@inproceedings{tong2024eyes,
  title={Eyes wide shut? exploring the visual shortcomings of multimodal llms},
  author={Tong, Shengbang and Liu, Zhuang and Zhai, Yuexiang and Ma, Yi and LeCun, Yann and Xie, Saining},
  booktitle={CVPR},
  year={2024}
}

@inproceedings{liu2023improved,
  title={Improved baselines with visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  booktitle={CVPR},
  year={2024}
}


@article{mckinzie2024mm1,
  title={Mm1: Methods, analysis \& insights from multimodal llm pre-training},
  author={McKinzie, Brandon and Gan, Zhe and Fauconnier, Jean-Philippe and Dodge, Sam and Zhang, Bowen and Dufter, Philipp and Shah, Dhruti and Du, Xianzhi and Peng, Futang and Weers, Floris and others},
  journal={arXiv preprint arXiv:2403.09611},
  year={2024}
}

@inproceedings{fang2023data,
  title={Data filtering networks},
  author={Fang, Alex and Jose, Albin Madappally and Jain, Amit and Schmidt, Ludwig and Toshev, Alexander and Shankar, Vaishaal},
  booktitle={ICLR},
  year={2024}
}
@article{gao2024sphinx,
  title={SPHINX-X: Scaling Data and Parameters for a Family of Multi-modal Large Language Models},
  author={Gao, Peng and Zhang, Renrui and Liu, Chris and Qiu, Longtian and Huang, Siyuan and Lin, Weifeng and Zhao, Shitian and Geng, Shijie and Lin, Ziyi and Jin, Peng and others},
  journal={arXiv preprint arXiv:2402.05935},
  year={2024}
}

@online{DatabricksBlog2023DollyV2,
    author    = {Mike Conover and Matt Hayes and Ankit Mathur and Jianwei Xie and Jun Wan and Sam Shah and Ali Ghodsi and Patrick Wendell and Matei Zaharia and Reynold Xin},
    title     = {Free Dolly: Introducing the World's First Truly Open Instruction-Tuned LLM},
    year      = {2023},
    url       = {https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm},
    urldate   = {2023-06-30}
}

@inproceedings{yue2023mammoth,
  title={Mammoth: Building math generalist models through hybrid instruction tuning},
  author={Yue, Xiang and Qu, Xingwei and Zhang, Ge and Fu, Yao and Huang, Wenhao and Sun, Huan and Su, Yu and Chen, Wenhu},
  booktitle={ICLR},
  year={2024}
}

@inproceedings{luo2023wizardcoder,
  title={Wizardcoder: Empowering code large language models with evol-instruct},
  author={Luo, Ziyang and Xu, Can and Zhao, Pu and Sun, Qingfeng and Geng, Xiubo and Hu, Wenxiang and Tao, Chongyang and Ma, Jing and Lin, Qingwei and Jiang, Daxin},
  booktitle={ICLR},
  year={2024}
}

@misc{mitra2024orcamath,
      title={Orca-Math: Unlocking the potential of SLMs in Grade School Math}, 
      author={Arindam Mitra and Hamed Khanpour and Corby Rosset and Ahmed Awadallah},
      year={2024},
      eprint={2402.14830},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@article{zheng2024opencodeinterpreter,
  title={OpenCodeInterpreter: Integrating Code Generation with Execution and Refinement},
  author={Zheng, Tianyu and Zhang, Ge and Shen, Tianhao and Liu, Xueling and Lin, Bill Yuchen and Fu, Jie and Chen, Wenhu and Yue, Xiang},
  journal={arXiv preprint arXiv:2402.14658},
  year={2024}
}

@misc{OpenOrca,
  title = {OpenOrca: An Open Dataset of GPT Augmented FLAN Reasoning Traces},
  author = {Wing Lian and Bleys Goodson and Eugene Pentland and Austin Cook and Chanvichet Vong and "Teknium"},
  year = {2023},
  publisher = {HuggingFace},
  journal = {HuggingFace repository},
  howpublished = {\url{https://https://huggingface.co/Open-Orca/OpenOrca}},
}

@misc{tang2025tulip,
        title     = {TULIP: Towards Unified Language-Image Pretraining},
        author    = {Zineng Tang and Long Lian and Seun Eisape and XuDong Wang and Roei Herzig and Adam Yala and Alane Suhr and Trevor Darrell and David M. Chan},
        institution = {University of California, Berkeley},
        year      = {2025},
        note      = {Preprint},
      }

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={ICML},
  year={2021},
}
@inproceedings{schuhmann2022laion,
  title={Laion-5b: An open large-scale dataset for training next generation image-text models},
  author={Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others},
  booktitle={NeurIPS},
  year={2022}
}
@inproceedings{zheng2024judging,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  booktitle={NeurIPS},
  year={2024}
}
@article{chiang2024chatbot,
  title={Chatbot arena: An open platform for evaluating llms by human preference},
  author={Chiang, Wei-Lin and Zheng, Lianmin and Sheng, Ying and Angelopoulos, Anastasios Nikolas and Li, Tianle and Li, Dacheng and Zhang, Hao and Zhu, Banghua and Jordan, Michael and Gonzalez, Joseph E and others},
  journal={arXiv preprint arXiv:2403.04132},
  year={2024}
}

@inproceedings{zhai2023sigmoid,
  title={Sigmoid loss for language image pre-training},
  author={Zhai, Xiaohua and Mustafa, Basil and Kolesnikov, Alexander and Beyer, Lucas},
  booktitle={ICCV},
  year={2023}
}
@article{sun2023eva,
  title={Eva-clip: Improved training techniques for clip at scale},
  author={Sun, Quan and Fang, Yuxin and Wu, Ledell and Wang, Xinlong and Cao, Yue},
  journal={arXiv preprint arXiv:2303.15389},
  year={2023}
}
@inproceedings{cherti2023reproducible,
  title={Reproducible scaling laws for contrastive language-image learning},
  author={Cherti, Mehdi and Beaumont, Romain and Wightman, Ross and Wortsman, Mitchell and Ilharco, Gabriel and Gordon, Cade and Schuhmann, Christoph and Schmidt, Ludwig and Jitsev, Jenia},
  booktitle={CVPR},
  year={2023}
}

@inproceedings{chen2021empirical,
  title={An empirical study of training self-supervised vision transformers},
  author={Chen, Xinlei and Xie, Saining and He, Kaiming},
  booktitle={ICCV},
  year={2021}
}

@inproceedings{oquab2023dinov2,
  title={Dinov2: Learning robust visual features without supervision},
  author={Oquab, Maxime and Darcet, Timoth{\'e}e and Moutakanni, Th{\'e}o and Vo, Huy and Szafraniec, Marc and Khalidov, Vasil and Fernandez, Pierre and Haziza, Daniel and Massa, Francisco and El-Nouby, Alaaeldin and others},
  booktitle={TMLR},
  year={2023}
}
@inproceedings{cunningham2023sparse,
  title={Sparse autoencoders find highly interpretable features in language models},
  author={Cunningham, Hoagy and Ewart, Aidan and Riggs, Logan and Huben, Robert and Sharkey, Lee},
  booktitle={ICLR},
  year={2024}
}
@inproceedings{assran2023self,
  title={Self-supervised learning from images with a joint-embedding predictive architecture},
  author={Assran, Mahmoud and Duval, Quentin and Misra, Ishan and Bojanowski, Piotr and Vincent, Pascal and Rabbat, Michael and LeCun, Yann and Ballas, Nicolas},
  booktitle={CVPR},
  year={2023}
}
@inproceedings{barstochastic,
  title={Stochastic positional embeddings improve masked image modeling},
  author={Bar, Amir and Bordes, Florian and Shocher, Assaf and Assran, Mido and Vincent, Pascal and Ballas, Nicolas and Darrell, Trevor and Globerson, Amir and LeCun, Yann},
  booktitle={ICML},
  year={2024}
}
@inproceedings{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  booktitle={ICLR},
  year={2021}
}
@inproceedings{jouppi2023tpu,
  title={Tpu v4: An optically reconfigurable supercomputer for machine learning with hardware support for embeddings},
  author={Jouppi, Norm and Kurian, George and Li, Sheng and Ma, Peter and Nagarajan, Rahul and Nai, Lifeng and Patil, Nishant and Subramanian, Suvinay and Swing, Andy and Towles, Brian and others},
  booktitle={Proceedings of the 50th Annual International Symposium on Computer Architecture},
  year={2023}
}
@article{zhao2023pytorch,
  title={Pytorch fsdp: experiences on scaling fully sharded data parallel},
  author={Zhao, Yanli and Gu, Andrew and Varma, Rohan and Luo, Liang and Huang, Chien-Chin and Xu, Min and Wright, Less and Shojanazeri, Hamid and Ott, Myle and Shleifer, Sam and others},
  journal={arXiv preprint arXiv:2304.11277},
  year={2023}
}
@article{zhou2023don,
  title={Don't Make Your LLM an Evaluation Benchmark Cheater},
  author={Zhou, Kun and Zhu, Yutao and Chen, Zhipeng and Chen, Wentong and Zhao, Wayne Xin and Chen, Xu and Lin, Yankai and Wen, Ji-Rong and Han, Jiawei},
  journal={arXiv preprint arXiv:2311.01964},
  year={2023}
}
@inproceedings{kirillov2023segment,
  title={Segment anything},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others},
  booktitle={ICCV},
  year={2023}
}
@article{birkl2023midas,
  title={Midas v3. 1--a model zoo for robust monocular relative depth estimation},
  author={Birkl, Reiner and Wofk, Diana and M{\"u}ller, Matthias},
  journal={arXiv preprint arXiv:2307.14460},
  year={2023}
}

@article{lasinger2019towards,
  title={Towards robust monocular depth estimation: Mixing datasets for zero-shot cross-dataset transfer},
  author={Lasinger, Katrin and Ranftl, Ren{\'e} and Schindler, Konrad and Koltun, Vladlen},
  journal={arXiv preprint arXiv:1907.01341},
  year={2019}
}


@Inproceedings{Rombach_2022_CVPR,
    author    = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj\"orn},
    title     = {High-Resolution Image Synthesis With Latent Diffusion Models},
    booktitle = {CVPR},
    year      = {2022}
}

@article{karamcheti2024prismatic,
  title={Prismatic vlms: Investigating the design space of visually-conditioned language models},
  author={Karamcheti, Siddharth and Nair, Suraj and Balakrishna, Ashwin and Liang, Percy and Kollar, Thomas and Sadigh, Dorsa},
  journal={arXiv preprint arXiv:2402.07865},
  year={2024}
}

@Inproceedings{zhai2023investigating,
  title={Investigating the catastrophic forgetting in multimodal large language models},
  author={Zhai, Yuexiang and Tong, Shengbang and Li, Xiao and Cai, Mu and Qu, Qing and Lee, Yong Jae and Ma, Yi},
  booktitle = {CPAL},
  year={2024}
}
@inproceedings{li2023internet,
    title={Internet Explorer: Targeted Representation Learning on the Open Web}, 
    author={Li, Alexander C and Brown, Ellis and Efros, Alexei A and Pathak, Deepak},
    booktitle={ICML},
    year={2023},
}
@misc{liu2024llavanext,
    title={LLaVA-NeXT: Improved reasoning, OCR, and world knowledge},
    url={https://llava-vl.github.io/blog/2024-01-30-llava-next/},
    author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Li, Bo and Zhang, Yuanhan and Shen, Sheng and Lee, Yong Jae},
    year={2024}
}
@article{lu2024deepseek,
  title={DeepSeek-VL: towards real-world vision-language understanding},
  author={Lu, Haoyu and Liu, Wen and Zhang, Bo and Wang, Bingxuan and Dong, Kai and Liu, Bo and Sun, Jingxiang and Ren, Tongzheng and Li, Zhuoshu and Sun, Yaofeng and others},
  journal={arXiv preprint arXiv:2403.05525},
  year={2024}
}
@inproceedings{li2023your,
  title={Your diffusion model is secretly a zero-shot classifier},
  author={Li, Alexander C and Prabhudesai, Mihir and Duggal, Shivam and Brown, Ellis and Pathak, Deepak},
  booktitle={ICCV},
  year={2023}
}
@inproceedings{chen2022pali,
  title={Pali: A jointly-scaled multilingual language-image model},
  author={Chen, Xi and Wang, Xiao and Changpinyo, Soravit and Piergiovanni, AJ and Padlewski, Piotr and Salz, Daniel and Goodman, Sebastian and Grycner, Adam and Mustafa, Basil and Beyer, Lucas and others},
  booktitle={ICLR},
  year={2023}
}
@article{murtagh2014ward,
  title={Ward’s hierarchical agglomerative clustering method: which algorithms implement Ward’s criterion?},
  author={Murtagh, Fionn and Legendre, Pierre},
  journal={Journal of classification},
  volume={31},
  pages={274--295},
  year={2014},
  publisher={Springer}
}
@article{llama3modelcard,

    title={Llama 3 Model Card},

    author={AI@Meta},
  
    year={2024},

    url = {https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md}

}

@misc{Gemini,
  title={Gemini},
  author={Google},
  year={2023},
  url={https://blog.google/technology/ai/google-gemini-ai/}
}

@article{qwen,
  title={Qwen Technical Report},
  author={Jinze Bai and Shuai Bai and Yunfei Chu and Zeyu Cui and Kai Dang and Xiaodong Deng and Yang Fan and Wenbin Ge and Yu Han and Fei Huang and Binyuan Hui and Luo Ji and Mei Li and Junyang Lin and Runji Lin and Dayiheng Liu and Gao Liu and Chengqiang Lu and Keming Lu and Jianxin Ma and Rui Men and Xingzhang Ren and Xuancheng Ren and Chuanqi Tan and Sinan Tan and Jianhong Tu and Peng Wang and Shijie Wang and Wei Wang and Shengguang Wu and Benfeng Xu and Jin Xu and An Yang and Hao Yang and Jian Yang and Shusheng Yang and Yang Yao and Bowen Yu and Hongyi Yuan and Zheng Yuan and Jianwei Zhang and Xingxuan Zhang and Yichang Zhang and Zhenru Zhang and Chang Zhou and Jingren Zhou and Xiaohuan Zhou and Tianhang Zhu},
  journal={arXiv preprint arXiv:2309.16609},
  year={2023}
}
@article{bai2023qwen,
  title={Qwen-vl: A versatile vision-language model for understanding, localization, text reading, and beyond},
  author={Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren},
  year={2023}
}
@inproceedings{dai2024instructblip,
  title={Instructblip: Towards general-purpose vision-language models with instruction tuning},
  author={Dai, Wenliang and Li, Junnan and Li, Dongxu and Tiong, Anthony Meng Huat and Zhao, Junqi and Wang, Weisheng and Li, Boyang and Fung, Pascale N and Hoi, Steven},
  booktitle={NeurIPS},
  year={2024}
}
@article{liu2023hidden,
  title={On the hidden mystery of ocr in large multimodal models},
  author={Liu, Yuliang and Li, Zhang and Li, Hongliang and Yu, Wenwen and Huang, Mingxin and Peng, Dezhi and Liu, Mingyu and Chen, Mingrui and Li, Chunyuan and Jin, Lianwen and others},
  journal={arXiv preprint arXiv:2305.07895},
  year={2023}
}
@article{ge2023planting,
  title={Planting a seed of vision in large language model},
  author={Ge, Yuying and Ge, Yixiao and Zeng, Ziyun and Wang, Xintao and Shan, Ying},
  journal={arXiv preprint arXiv:2307.08041},
  year={2023}
}

@inproceedings{wu2023vstar,
  title={V*: Guided Visual Search as a Core Mechanism in Multimodal LLMs},
  author={Wu, Penghao and Xie, Saining},
  booktitle={CVPR},
  year={2024}
}
@inproceedings{jaegle2021perceiver,
  title={Perceiver: General perception with iterative attention},
  author={Jaegle, Andrew and Gimeno, Felix and Brock, Andy and Vinyals, Oriol and Zisserman, Andrew and Carreira, Joao},
  booktitle={ICML},
  year={2021},
}
@article{young2024yi,
  title={Yi: Open foundation models by 01. ai},
  author={Young, Alex and Chen, Bei and Li, Chao and Huang, Chengen and Zhang, Ge and Zhang, Guanwei and Li, Heng and Zhu, Jiangcheng and Chen, Jianqun and Chang, Jing and others},
  journal={arXiv preprint arXiv:2403.04652},
  year={2024}
}
@inproceedings{zhai2024fine,
  title={Fine-Tuning Large Vision-Language Models as Decision-Making Agents via Reinforcement Learning},
  author={Zhai, Yuexiang and Bai, Hao and Lin, Zipeng and Pan, Jiayi and Tong, Shengbang and Zhou, Yifei and Suhr, Alane and Xie, Saining and LeCun, Yann and Ma, Yi and others},
  booktitle={NeurIPS},
  year={2024}
}
@inproceedings{lu2023mathvista,
  title={Mathvista: Evaluating mathematical reasoning of foundation models in visual contexts},
  author={Lu, Pan and Bansal, Hritik and Xia, Tony and Liu, Jiacheng and Li, Chunyuan and Hajishirzi, Hannaneh and Cheng, Hao and Chang, Kai-Wei and Galley, Michel and Gao, Jianfeng},
  booktitle={ICLR},
  year={2023}
}
@inproceedings{liu2023mmbench,
  title={Mmbench: Is your multi-modal model an all-around player?},
  author={Liu, Yuan and Duan, Haodong and Zhang, Yuanhan and Li, Bo and Zhang, Songyang and Zhao, Wangbo and Yuan, Yike and Wang, Jiaqi and He, Conghui and Liu, Ziwei and others},
  booktitle={ECCV},
  year={2024}
}

@inproceedings{alayrac2022flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  booktitle={NeurIPS},
  year={2022}
}

@inproceedings{li2023oxfordtvg,
  title={OxfordTVG-HIC: Can Machine Make Humorous Captions from Images?},
  author={Li, Runjia and Sun, Shuyang and Elhoseiny, Mohamed and Torr, Philip},
  booktitle={ICCV},
  year={2023}
}
@inproceedings{gadre2024datacomp,
  title={Datacomp: In search of the next generation of multimodal datasets},
  author={Gadre, Samir Yitzhak and Ilharco, Gabriel and Fang, Alex and Hayase, Jonathan and Smyrnis, Georgios and Nguyen, Thao and Marten, Ryan and Wortsman, Mitchell and Ghosh, Dhruba and Zhang, Jieyu and others},
  booktitle={NeurIPS},
  year={2024}
}
@article{banani2024probing,
  title={Probing the 3D Awareness of Visual Foundation Models},
  author={Banani, Mohamed El and Raj, Amit and Maninis, Kevis-Kokitsi and Kar, Abhishek and Li, Yuanzhen and Rubinstein, Michael and Sun, Deqing and Guibas, Leonidas and Johnson, Justin and Jampani, Varun},
  journal={arXiv preprint arXiv:2404.08636},
  year={2024}
}
@misc{OpenAI2022ChatGPT,
  title={ChatGPT},
  author={OpenAI},
  year={2022},
  url={https://openai.com/blog/chatgpt}
}
@misc{StabilityAI2024SD35,
  title={Stable Diffusion 3.5},
  author={Stability AI},
  year={2024},
  url={https://stability.ai/news/introducing-stable-diffusion-3-5}
}
@article{roberts2019exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Roberts, Adam and Raffel, Colin and Lee, Katherine and Matena, Michael and Shazeer, Noam and Liu, Peter J and Narang, Sharan and Li, Wei and Zhou, Yanqi},
  journal={JMLR},
  year={2019}
}
@misc{Taori2023Alpaca,
  title={Alpaca: A Strong, Replicable Instruction-Following Model},
  author={Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto},
  year={2023},
  url={https://crfm.stanford.edu/2023/03/13/alpaca.html}
}
@inproceedings{zhou2024lima,
  title={Lima: Less is more for alignment},
  author={Zhou, Chunting and Liu, Pengfei and Xu, Puxin and Iyer, Srinivasan and Sun, Jiao and Mao, Yuning and Ma, Xuezhe and Efrat, Avia and Yu, Ping and Yu, Lili and others},
  booktitle={NeurIPS},
  year={2024}
}


@misc{Sanseviero2024LLM,
  title={LLM Evals and Benchmarking},
  author={Omar Sanseviero},
  year={2022},
  url={https://osanseviero.github.io/hackerllama/}
}

@article{rajamanoharan2024improving,
  title={Improving dictionary learning with gated sparse autoencoders},
  author={Rajamanoharan, Senthooran and Conmy, Arthur and Smith, Lewis and Lieberum, Tom and Varma, Vikrant and Kram{\'a}r, J{\'a}nos and Shah, Rohin and Nanda, Neel},
  journal={arXiv preprint arXiv:2404.16014},
  year={2024}
}
@misc{grok,
  title={grok},
  author={xAI},
  year={2024},
  url={https://x.ai/blog/grok-1.5v}
}
@inproceedings{singh2019towards,
  title={Towards vqa models that can read},
  author={Singh, Amanpreet and Natarajan, Vivek and Shah, Meet and Jiang, Yu and Chen, Xinlei and Batra, Dhruv and Parikh, Devi and Rohrbach, Marcus},
  booktitle={CVPR},
  year={2019}
}
@article{chang2024survey,
  title={A survey on evaluation of large language models},
  author={Chang, Yupeng and Wang, Xu and Wang, Jindong and Wu, Yuan and Yang, Linyi and Zhu, Kaijie and Chen, Hao and Yi, Xiaoyuan and Wang, Cunxiang and Wang, Yidong and others},
  journal={ACM Transactions on Intelligent Systems and Technology},
  volume={15},
  number={3},
  pages={1--45},
  year={2024},
  publisher={ACM New York, NY}
}
@inproceedings{sun2024generative,
  title={Generative multimodal models are in-context learners},
  author={Sun, Quan and Cui, Yufeng and Zhang, Xiaosong and Zhang, Fan and Yu, Qiying and Wang, Yueze and Rao, Yongming and Liu, Jingjing and Huang, Tiejun and Wang, Xinlong},
  booktitle={CVPR},
  year={2024}
}
@inproceedings{sun2023generative,
  title={Generative pretraining in multimodality},
  author={Sun, Quan and Yu, Qiying and Cui, Yufeng and Zhang, Fan and Zhang, Xiaosong and Wang, Yueze and Gao, Hongcheng and Liu, Jingjing and Huang, Tiejun and Wang, Xinlong},
  booktitle={ICLR},
  year={2024}
}
@inproceedings{dong2023dreamllm,
  title={Dreamllm: Synergistic multimodal comprehension and creation},
  author={Dong, Runpei and Han, Chunrui and Peng, Yuang and Qi, Zekun and Ge, Zheng and Yang, Jinrong and Zhao, Liang and Sun, Jianjian and Zhou, Hongyu and Wei, Haoran and others},
  booktitle={ICLR},
  year={2024}
}

@inproceedings{shao2024visual,
  title={Visual cot: Advancing multi-modal language models with a comprehensive dataset and benchmark for chain-of-thought reasoning},
  author={Shao, Hao and Qian, Shengju and Xiao, Han and Song, Guanglu and Zong, Zhuofan and Wang, Letian and Liu, Yu and Li, Hongsheng},
  booktitle={NeurIPS},
  year={2024}
}
@inproceedings{miech2019howto100m,
  title={Howto100m: Learning a text-video embedding by watching hundred million narrated video clips},
  author={Miech, Antoine and Zhukov, Dimitri and Alayrac, Jean-Baptiste and Tapaswi, Makarand and Laptev, Ivan and Sivic, Josef},
  booktitle={ICCV},
  year={2019}
}
@article{wang2024emu3,
  title={Emu3: Next-token prediction is all you need},
  author={Wang, Xinlong and Zhang, Xiaosong and Luo, Zhengxiong and Sun, Quan and Cui, Yufeng and Wang, Jinsheng and Zhang, Fan and Wang, Yueze and Li, Zhen and Yu, Qiying and others},
  journal={arXiv preprint arXiv:2409.18869},
  year={2024}
}
@inproceedings{kar2025brave,
  title={BRAVE: Broadening the visual encoding of vision-language models},
  author={Kar, O{\u{g}}uzhan Fatih and Tonioni, Alessio and Poklukar, Petra and Kulshrestha, Achin and Zamir, Amir and Tombari, Federico},
  booktitle={ECCV},
  year={2025},
}

@inproceedings{laurenccon2024obelics,
  title={Obelics: An open web-scale filtered dataset of interleaved image-text documents},
  author={Lauren{\c{c}}on, Hugo and Saulnier, Lucile and Tronchon, L{\'e}o and Bekman, Stas and Singh, Amanpreet and Lozhkov, Anton and Wang, Thomas and Karamcheti, Siddharth and Rush, Alexander and Kiela, Douwe and others},
  booktitle={NeurIPS},
  year={2024}
}
@inproceedings{li2024mvbench,
  title={Mvbench: A comprehensive multi-modal video understanding benchmark},
  author={Li, Kunchang and Wang, Yali and He, Yinan and Li, Yizhuo and Wang, Yi and Liu, Yi and Wang, Zun and Xu, Jilan and Chen, Guo and Luo, Ping and others},
  booktitle={CVPR},
  year={2024}
}
@inproceedings{goyal2017something,
  title={The" something something" video database for learning and evaluating visual common sense},
  author={Goyal, Raghav and Ebrahimi Kahou, Samira and Michalski, Vincent and Materzynska, Joanna and Westphal, Susanne and Kim, Heuna and Haenel, Valentin and Fruend, Ingo and Yianilos, Peter and Mueller-Freitag, Moritz and others},
  booktitle={ICCV},
  year={2017}
}
@inproceedings{zohar2024videostar,
    title = {Video-STaR: Self-Training Enables Video Instruction Tuning with Any Supervision},
    author = {Zohar, Orr and Wang, Xiaohan and Bitton, Yonatan and Szpektor, Idan and Yeung-levy, Serena},
    year = {2024},
    booktitle = {arXiv preprint arXiv:2407.06189},
}
@misc{OpenAI2024gpt4o,
  title={gpt4o},
  author={OpenAI},
  year={2024},
  url={https://openai.com/index/hello-gpt-4o/}
}
@misc{Anthropic2024Claude,
  title={Claude},
  author={Anthropic},
  year={2024},
  url={https://www.anthropic.com/news/claude-3-5-sonnet}
}


@article{touvron2023llama,
  title={{LLaMA}: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}
@article{touvron2023llama2,
  title={{LLaMA} 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  booktitle={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@misc{li2024llavanext-strong,
    title={LLaVA-NeXT: Stronger LLMs Supercharge Multimodal Capabilities in the Wild},
    url={https://llava-vl.github.io/blog/2024-05-10-llava-next-stronger-llms/},
    author={Li, Bo and Zhang, Kaichen and Zhang, Hao and Guo, Dong and Zhang, Renrui and Li, Feng and Zhang, Yuanhan and Liu, Ziwei and Li, Chunyuan},
    year={2024}
}
@inproceedings{yue2023mmmu,
  title={Mmmu: A massive multi-discipline multimodal understanding and reasoning benchmark for expert agi},
  author={Yue, Xiang and Ni, Yuansheng and Zhang, Kai and Zheng, Tianyu and Liu, Ruoqi and Zhang, Ge and Stevens, Samuel and Jiang, Dongfu and Ren, Weiming and Sun, Yuxuan and others},
  booktitle={CVPR},
  year={2024}
}
@article{hiippala2021ai2d,
  title={AI2D-RST: A multimodal corpus of 1000 primary school science diagrams},
  author={Hiippala, Tuomo and Alikhani, Malihe and Haverinen, Jonas and Kalliokoski, Timo and Logacheva, Evanfiya and Orekhova, Serafina and Tuomainen, Aino and Stone, Matthew and Bateman, John A},
  journal={Language Resources and Evaluation},
  volume={55},
  pages={661--688},
  year={2021},
  publisher={Springer}
}

@inproceedings{brazil2023omni3d,
  title={Omni3d: A large benchmark and model for 3d object detection in the wild},
  author={Brazil, Garrick and Kumar, Abhinav and Straub, Julian and Ravi, Nikhila and Johnson, Justin and Gkioxari, Georgia},
  booktitle={CVPR},
  year={2023}
}

@article{zhou2019semantic,
  title={Semantic understanding of scenes through the ade20k dataset},
  author={Zhou, Bolei and Zhao, Hang and Puig, Xavier and Xiao, Tete and Fidler, Sanja and Barriuso, Adela and Torralba, Antonio},
  journal={IJCV},
  year={2019},
}

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={ECCV},
  year={2014}
}

@article{fu2024blink,
  title={BLINK: Multimodal Large Language Models Can See but Not Perceive},
  author={Fu, Xingyu and Hu, Yushi and Li, Bangzheng and Feng, Yu and Wang, Haoyu and Lin, Xudong and Roth, Dan and Smith, Noah A and Ma, Wei-Chiu and Krishna, Ranjay},
  journal={arXiv preprint arXiv:2404.12390},
  year={2024}
}


@article{russakovsky2015imagenet,
  title={Imagenet large scale visual recognition challenge},
  author={Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
  journal={IJCV},
  year={2015},
}

@book{aquinas,
  title     = {Quaestiones Disputatae de Veritate},
  author    = {Thomas Aquinas},
  year      = 1259,
  address   = "q.2 a.3 arg.19"
}
@book{aristotle-metaphysics-350BCE,
  added-at = {2011-06-06T22:32:14.000+0200},
  author = {Aristotle},
  biburl = {https://www.bibsonomy.org/bibtex/205aed2bf4d0b39ab66d998142b5608cd/mhwombat},
  editor = {by W. D. Ross, Translated},
  groups = {public},
  interhash = {9a4a19db0a4c4ac757b2e4fb7dddadeb},
  intrahash = {05aed2bf4d0b39ab66d998142b5608cd},
  keywords = {MSc _checked philosophy},
  publisher = {The Internet Classics Archive},
  timestamp = {2016-07-12T19:25:30.000+0200},
  title = {Metaphysics},
  url = {http://classics.mit.edu/Aristotle/metaphysics.html},
  username = {mhwombat},
  year = {350BCE}
}

@book{parker2003blink,
  title={In the blink of an eye: how vision sparked the big bang of evolution},
  author={Parker, Andrew},
  year={2003}
}

@article{chalmers2023does,
	author = {David J. Chalmers},
	journal = {Proceedings and Addresses of the American Philosophical Association},
	pages = {22--45},
	title = {Does Thought Require Sensory Grounding? From Pure Thinkers to Large Language Models},
	volume = {97},
	year = {2023}
}

@book{piaget1952origins,
  title={The origins of intelligence in children},
  author={Piaget, Jean and Cook, Margaret and others},
  volume={8},
  number={5},
  year={1952},
  publisher={International Universities Press New York}
}

@inproceedings{hoffmann2022training,
  title={Training compute-optimal large language models},
  author={Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and others},
  booktitle={NeurIPS},
  year={2023}
}

@inproceedings{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  booktitle={NeurIPS},
  year={2020}
}

@article{laurenccon2024matters,
  title={What matters when building vision-language models?},
  author={Lauren{\c{c}}on, Hugo and Tronchon, L{\'e}o and Cord, Matthieu and Sanh, Victor},
  journal={arXiv preprint arXiv:2405.02246},
  year={2024}
}

@inproceedings{girshick2014rich,
  title={Rich feature hierarchies for accurate object detection and semantic segmentation},
  author={Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
  booktitle={CVPR},
  year={2014}
}

@inproceedings{mathew2022infographicvqa,
  title={Infographicvqa},
  author={Mathew, Minesh and Bagal, Viraj and Tito, Rub{\`e}n and Karatzas, Dimosthenis and Valveny, Ernest and Jawahar, CV},
  booktitle={WACV},
  year={2022}
}

@article{chen2024we,
  title={Are We on the Right Way for Evaluating Large Vision-Language Models?},
  author={Chen, Lin and Li, Jinsong and Dong, Xiaoyi and Zhang, Pan and Zang, Yuhang and Chen, Zehui and Duan, Haodong and Wang, Jiaqi and Qiao, Yu and Lin, Dahua and others},
  journal={arXiv preprint arXiv:2403.20330},
  year={2024}
}
@article{wu2024janus,
  title={Janus: Decoupling visual encoding for unified multimodal understanding and generation},
  author={Wu, Chengyue and Chen, Xiaokang and Wu, Zhiyu and Ma, Yiyang and Liu, Xingchao and Pan, Zizheng and Liu, Wen and Xie, Zhenda and Yu, Xingkai and Ruan, Chong and others},
  journal={arXiv preprint arXiv:2410.13848},
  year={2024}
}
@inproceedings{huh2024platonic,
  title={The platonic representation hypothesis},
  author={Huh, Minyoung and Cheung, Brian and Wang, Tongzhou and Isola, Phillip},
  booktitle={ICML},
  year={2024}
}

@article{agrawal2024pixtral,
  title={Pixtral 12B},
  author={Agrawal, Pravesh and Antoniak, Szymon and Hanna, Emma Bou and Chaplot, Devendra and Chudnovsky, Jessica and Garg, Saurabh and Gervet, Theophile and Ghosh, Soham and H{\'e}liou, Am{\'e}lie and Jacob, Paul and others},
  journal={arXiv preprint arXiv:2410.07073},
  year={2024}
}
@inproceedings{lu2024unified,
  title={Unified-IO 2: Scaling Autoregressive Multimodal Models with Vision Language Audio and Action},
  author={Lu, Jiasen and Clark, Christopher and Lee, Sangho and Zhang, Zichen and Khosla, Savya and Marten, Ryan and Hoiem, Derek and Kembhavi, Aniruddha},
  booktitle={CVPR},
  year={2024}
}
@article{aghajanyan2022cm3,
  title={Cm3: A causal masked multimodal model of the internet},
  author={Aghajanyan, Armen and Huang, Bernie and Ross, Candace and Karpukhin, Vladimir and Xu, Hu and Goyal, Naman and Okhonko, Dmytro and Joshi, Mandar and Ghosh, Gargi and Lewis, Mike and others},
  journal={arXiv preprint arXiv:2201.07520},
  year={2022}
}

@inproceedings{lu2022unified,
  title={Unified-io: A unified model for vision, language, and multi-modal tasks},
  author={Lu, Jiasen and Clark, Christopher and Zellers, Rowan and Mottaghi, Roozbeh and Kembhavi, Aniruddha},
  booktitle={ICLR},
  year={2022}
}

@inproceedings{agrawal2018don,
  title={Don't just assume; look and answer: Overcoming priors for visual question answering},
  author={Agrawal, Aishwarya and Batra, Dhruv and Parikh, Devi and Kembhavi, Aniruddha},
  booktitle={CVPR},
  year={2018}
}
@inproceedings{chen2024sharegpt4video,
  title={Sharegpt4video: Improving video understanding and generation with better captions},
  author={Chen, Lin and Wei, Xilin and Li, Jinsong and Dong, Xiaoyi and Zhang, Pan and Zang, Yuhang and Chen, Zehui and Duan, Haodong and Lin, Bin and Tang, Zhenyu and others},
  booktitle={NeurIPS},
  year={2024}
}
@inproceedings{krojer2024learning,
  title={Learning Action and Reasoning-Centric Image Editing from Videos and Simulations},
  author={Krojer, Benno and Vattikonda, Dheeraj and Lara, Luis and Jampani, Varun and Portelance, Eva and Pal, Christopher and Reddy, Siva},
  booktitle={NeurIPS},
  year={2024}
}

@inproceedings{hessel2021clipscore,
  title={Clipscore: A reference-free evaluation metric for image captioning},
  author={Hessel, Jack and Holtzman, Ari and Forbes, Maxwell and Bras, Ronan Le and Choi, Yejin},
  booktitle={EMNLP},
  year={2021}
}

@inproceedings{brooks2023instructpix2pix,
  title={Instructpix2pix: Learning to follow image editing instructions},
  author={Brooks, Tim and Holynski, Aleksander and Efros, Alexei A},
  booktitle={CVPR},
  year={2023}
}c  
@inproceedings{goyal2017making,
  title={Making the v in vqa matter: Elevating the role of image understanding in visual question answering},
  author={Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
  booktitle={CVPR},
  year={2017}
}
@misc{AllenZhu-icml2024-tutorial,
    author = {{Allen-Zhu}, Zeyuan},
    title = {{ICML 2024 Tutorial: Physics of Language Models}},
    year = {2024},
    month = {July},
    note = {Project page: \url{https://physics.allen-zhu.com/}}
}
@article{YXLA2024-gsm1,
  author = {Ye, Tian and Xu, Zicheng and Li, Yuanzhi and {Allen-Zhu}, Zeyuan},
  title = {{Physics of Language Models: Part 2.1, Grade-School Math and the Hidden Reasoning Process}},
  journal = {ArXiv e-prints},
  year = 2024,
  month = jul,
  volume = {abs/2407.20311},
  note = {Full version available at \url{http://arxiv.org/abs/2407.20311}}
}

@inproceedings{majumdar2024openeqa,
  title={OpenEQA: Embodied Question Answering in the Era of Foundation Models},
  author={Majumdar, Arjun and Ajay, Anurag and Zhang, Xiaohan and Putta, Pranav and Yenamandra, Sriram and Henaff, Mikael and Silwal, Sneha and Mcvay, Paul and Maksymets, Oleksandr and Arnaud, Sergio and others},
  booktitle={2nd Workshop on Mobile Manipulation and Embodied Intelligence at ICRA 2024},
  year={2024}
}

@article{minigemini,
  title={Mini-gemini: Mining the potential of multi-modality vision language models},
  author={Li, Yanwei and Zhang, Yuechen and Wang, Chengyao and Zhong, Zhisheng and Chen, Yixin and Chu, Ruihang and Liu, Shaoteng and Jia, Jiaya},
  journal={arXiv preprint arXiv:2403.18814},
  year={2024}
}
@article{geirhos2020shortcut,
  title={Shortcut learning in deep neural networks},
  author={Geirhos, Robert and Jacobsen, J{\"o}rn-Henrik and Michaelis, Claudio and Zemel, Richard and Brendel, Wieland and Bethge, Matthias and Wichmann, Felix A},
  journal={Nature Machine Intelligence},
  year={2020},
  publisher={Nature Publishing Group UK London}
}
@inproceedings{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  booktitle={NeurIPS},
  year={2022}
}

# omni3d assets
@inproceedings{Geiger2012CVPR,
  author = {Andreas Geiger and Philip Lenz and Raquel Urtasun},
  title = {Are we ready for Autonomous Driving? The KITTI Vision Benchmark Suite},
  booktitle = {CVPR},
  year = {2012}
}
@inproceedings{caesar2020nuscenes,
  title={nuscenes: A multimodal dataset for autonomous driving},
  author={Caesar, Holger and Bankiti, Varun and Lang, Alex H and Vora, Sourabh and Liong, Venice Erin and Xu, Qiang and Krishnan, Anush and Pan, Yu and Baldan, Giancarlo and Beijbom, Oscar},
  booktitle={CVPR},
  year={2020}
}
@inproceedings{song2015sun,
  title={Sun rgb-d: A rgb-d scene understanding benchmark suite},
  author={Song, Shuran and Lichtenberg, Samuel P and Xiao, Jianxiong},
  booktitle={CVPR},
  year={2015}
}
@inproceedings{dehghan2021arkitscenes,
  title={{ARK}itScenes - A Diverse Real-World Dataset for 3D Indoor Scene Understanding Using Mobile {RGB}-D Data},
  author={Gilad Baruch and Zhuoyuan Chen and Afshin Dehghan and Tal Dimry and Yuri Feigin and Peter Fu and Thomas Gebauer and Brandon Joffe and Daniel Kurz and Arik Schwartz and Elad Shulman},
  booktitle={NeurIPS},
  year={2021},
}
@inproceedings{hypersim,
  author    = {Mike Roberts AND Jason Ramapuram AND Anurag Ranjan AND Atulit Kumar AND
                 Miguel Angel Bautista AND Nathan Paczan AND Russ Webb AND Joshua M. Susskind},
  title     = {{Hypersim}: {A} Photorealistic Synthetic Dataset for Holistic Indoor Scene Understanding},
  booktitle = {ICCV},
  year      = {2021},
}
@article{objectron2021,
  title={Objectron: A Large Scale Dataset of Object-Centric Videos in the Wild with Pose Annotations},
  author={Ahmadyan, Adel and Zhang, Liangkai and Ablavatski, Artsiom and Wei, Jianing and Grundmann, Matthias},
  journal={CVPR},
  year={2021},
}

@article{wang2024qwen2,
  title={Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at Any Resolution},
  author={Wang, Peng and Bai, Shuai and Tan, Sinan and Wang, Shijie and Fan, Zhihao and Bai, Jinze and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and others},
  journal={arXiv preprint arXiv:2409.12191},
  year={2024}
}
@article{li2024llava,
  title={Llava-onevision: Easy visual task transfer},
  author={Li, Bo and Zhang, Yuanhan and Guo, Dong and Zhang, Renrui and Li, Feng and Zhang, Hao and Zhang, Kaichen and Li, Yanwei and Liu, Ziwei and Li, Chunyuan},
  journal={arXiv preprint arXiv:2408.03326},
  year={2024}
}
@inproceedings{tong2024cambrian,
  title={Cambrian-1: A fully open, vision-centric exploration of multimodal llms},
  author={Tong, Shengbang and Brown, Ellis and Wu, Penghao and Woo, Sanghyun and Middepogu, Manoj and Akula, Sai Charitha and Yang, Jihan and Yang, Shusheng and Iyer, Adithya and Pan, Xichen and others},
  booktitle={NeurIPS},
  year={2024}
}

@inproceedings{li2023blip,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  booktitle={ICML},
  year={2023},
}

@article{zhou2024transfusion,
  title={Transfusion: Predict the next token and diffuse images with one multi-modal model},
  author={Zhou, Chunting and Yu, Lili and Babu, Arun and Tirumala, Kushal and Yasunaga, Michihiro and Shamis, Leonid and Kahn, Jacob and Ma, Xuezhe and Zettlemoyer, Luke and Levy, Omer},
  journal={arXiv preprint arXiv:2408.11039},
  year={2024}
}

@article{wu2024vila,
  title={Vila-u: a unified foundation model integrating visual understanding and generation},
  author={Wu, Yecheng and Zhang, Zhuoyang and Chen, Junyu and Tang, Haotian and Li, Dacheng and Fang, Yunhao and Zhu, Ligeng and Xie, Enze and Yin, Hongxu and Yi, Li and others},
  journal={arXiv preprint arXiv:2409.04429},
  year={2024}
}

@article{xie2024show,
  title={Show-o: One single transformer to unify multimodal understanding and generation},
  author={Xie, Jinheng and Mao, Weijia and Bai, Zechen and Zhang, David Junhao and Wang, Weihao and Lin, Kevin Qinghong and Gu, Yuchao and Chen, Zhijie and Yang, Zhenheng and Shou, Mike Zheng},
  journal={arXiv preprint arXiv:2408.12528},
  year={2024}
}

@article{baddeley1992working,
  title={Working memory},
  author={Baddeley, Alan},
  journal={Science},
  volume={255},
  number={5044},
  pages={556--559},
  year={1992},
  publisher={American Association for the Advancement of Science}
}


@article{amit2017asymmetrical,
  title={An asymmetrical relationship between verbal and visual thinking: Converging evidence from behavior and fMRI},
  author={Amit, Elinor and Hoeflin, Caitlyn and Hamzah, Nada and Fedorenko, Evelina},
  journal={NeuroImage},
  volume={152},
  pages={619--627},
  year={2017},
  publisher={Elsevier}
}
@book{paivio1990mental,
  title={Mental representations: A dual coding approach},
  author={Paivio, Allan},
  year={1990},
  publisher={Oxford university press}
}
@article{ganis2004brain,
  title={Brain areas underlying visual mental imagery and visual perception: an fMRI study},
  author={Ganis, Giorgio and Thompson, William L and Kosslyn, Stephen M},
  journal={Cognitive Brain Research},
  volume={20},
  number={2},
  pages={226--241},
  year={2004},
  publisher={Elsevier}
}

@article{lecun2022path,
  title={A path towards autonomous machine intelligence version 0.9. 2, 2022-06-27},
  author={LeCun, Yann},
  journal={Open Review},
  volume={62},
  number={1},
  pages={1--62},
  year={2022}
}

@article{amit2009distance,
  title={Distance-dependent processing of pictures and words.},
  author={Amit, Elinor and Algom, Daniel and Trope, Yaacov},
  journal={Journal of Experimental Psychology: General},
  volume={138},
  number={3},
  pages={400},
  year={2009},
  publisher={American Psychological Association}
}
@article{amit2013use,
  title={The use of visual and verbal means of communication across psychological distance},
  author={Amit, Elinor and Wakslak, Cheryl and Trope, Yaacov},
  journal={Personality and Social Psychology Bulletin},
  volume={39},
  number={1},
  pages={43--56},
  year={2013},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}
@article{ormazabal2024reka,
  title={Reka Core, Flash, and Edge: A Series of Powerful Multimodal Language Models},
  author={Ormazabal, Aitor and Zheng, Che and d'Autume, Cyprien de Masson and Yogatama, Dani and Fu, Deyu and Ong, Donovan and Chen, Eric and Lamprecht, Eugenie and Pham, Hai and Ong, Isaac and others},
  journal={arXiv preprint arXiv:2404.12387},
  year={2024}
}
@article{chowdhery2022palm,
  title={Palm: Scaling language modeling with pathways. arXiv 2022},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  volume={10},
  pages={1},
  year={2022}
}
@article{liu2024world,
  title={World model on million-length video and language with ringattention},
  author={Liu, Hao and Yan, Wilson and Zaharia, Matei and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2402.08268},
  year={2024}
}
@inproceedings{tschannen2024image,
  title={Image captioners are scalable vision learners too},
  author={Tschannen, Michael and Kumar, Manoj and Steiner, Andreas and Zhai, Xiaohua and Houlsby, Neil and Beyer, Lucas},
  booktitle={NeurIPS},
  year={2024}
}

@article{fini2024multimodal,
  title={Multimodal autoregressive pre-training of large vision encoders},
  author={Fini, Enrico and Shukor, Mustafa and Li, Xiujun and Dufter, Philipp and Klein, Michal and Haldimann, David and Aitharaju, Sai and da Costa, Victor Guilherme Turrisi and B{\'e}thune, Louis and Gan, Zhe and others},
  journal={arXiv preprint arXiv:2411.14402},
  year={2024}
}

@article{lecun1998mnist,
  title={The MNIST database of handwritten digits},
  author={LeCun, Yann},
  journal={http://yann. lecun. com/exdb/mnist/},
  year={1998}
}
@article{wang2025scaling,
  title={Scaling Pre-training to One Hundred Billion Data for Vision Language Models},
  author={Wang, Xiao and Alabdulmohsin, Ibrahim and Salz, Daniel and Li, Zhe and Rong, Keran and Zhai, Xiaohua},
  journal={arXiv preprint arXiv:2502.07617},
  year={2025}
}

@inproceedings{doersch2015unsupervised,
  title={Unsupervised visual representation learning by context prediction},
  author={Doersch, Carl and Gupta, Abhinav and Efros, Alexei A},
  booktitle={ICCV},
  year={2015}
}
@inproceedings{misra2019self,
  title={Self-supervised learning of pretext-invariant representations.},
  author={Misra, Ishan and Van Der Maaten, Laurens},
  booktitle={CVPR},
  year={2020}
}
@inproceedings{garrido2022duality,
  title={On the duality between contrastive and non-contrastive self-supervised learning},
  author={Garrido, Quentin and Chen, Yubei and Bardes, Adrien and Najman, Laurent and Lecun, Yann},
  booktitle={ICLR},
  year={2023}
}

@article{chen2022bag,
  title={Bag of image patch embedding behind the success of self-supervised learning},
  author={Chen, Yubei and Bardes, Adrien and Li, Zengyi and LeCun, Yann},
  journal={arXiv preprint arXiv:2206.08954},
  year={2022}
}
@article{zhou2021ibot,
  title={ibot: Image bert pre-training with online tokenizer},
  author={Zhou, Jinghao and Wei, Chen and Wang, Huiyu and Shen, Wei and Xie, Cihang and Yuille, Alan and Kong, Tao},
  journal={arXiv preprint arXiv:2111.07832},
  year={2021}
}
@article{carreira2024scaling,
  title={Scaling 4D Representations},
  author={Carreira, Jo{\~a}o and Gokay, Dilara and King, Michael and Zhang, Chuhan and Rocco, Ignacio and Mahendran, Aravindh and Keck, Thomas Albert and Heyward, Joseph and Koppula, Skanda and Pot, Etienne and others},
  journal={arXiv preprint arXiv:2412.15212},
  year={2024}
}
@inproceedings{wei2022masked,
  title={Masked feature prediction for self-supervised visual pre-training},
  author={Wei, Chen and Fan, Haoqi and Xie, Saining and Wu, Chao-Yuan and Yuille, Alan and Feichtenhofer, Christoph},
  booktitle={CVPR},
  year={2022}
}
@inproceedings{hendrycks2019natural,
  title={Natural adversarial examples. 2021 IEEE},
  author={Hendrycks, Dan and Zhao, Kevin and Basart, Steven and Steinhardt, Jacob and Song, Dawn Xiaodong},
  booktitle={CVPR},
  year={2019}
}
@inproceedings{hendrycks2020many,
  title={The many faces of robustness: A critical analysis of out-of-distribution generalization. 2021 IEEE},
  author={Hendrycks, Dan and Basart, Steven and Mu, Norman and Kadavath, Saurav and Wang, Frank and Dorundo, Evan and Desai, Rahul and Zhu, Tyler and Parajuli, Samyak and Guo, Mike and others},
  booktitle={ICCV},
  year={2020}
}
@inproceedings{bossard2014food,
  title={Food-101--mining discriminative components with random forests},
  author={Bossard, Lukas and Guillaumin, Matthieu and Van Gool, Luc},
  booktitle={ECCV},
  year={2014},
}
@inproceedings{wang2015unsupervised,
  title={Unsupervised learning of visual representations using videos},
  author={Wang, Xiaolong and Gupta, Abhinav},
  booktitle={ICCV},
  year={2015}
}

@inproceedings{cordts2016cityscapes,
  title={The cityscapes dataset for semantic urban scene understanding},
  author={Cordts, Marius and Omran, Mohamed and Ramos, Sebastian and Rehfeld, Timo and Enzweiler, Markus and Benenson, Rodrigo and Franke, Uwe and Roth, Stefan and Schiele, Bernt},
  booktitle={CVPR},
  year={2016}
}

@article{everingham2010pascal,
  title={The pascal visual object classes (voc) challenge},
  author={Everingham, Mark and Van Gool, Luc and Williams, Christopher KI and Winn, John and Zisserman, Andrew},
  journal={IJCV},
  year={2010},
}

@inproceedings{shi2024we,
  title={When do we not need larger vision models?},
  author={Shi, Baifeng and Wu, Ziyang and Mao, Maolin and Wang, Xin and Darrell, Trevor},
  booktitle={ECCV},
  year={2024},
}

@article{geiger2013vision,
  title={Vision meets robotics: The KITTI dataset},
  author={Geiger, Andreas and Lenz, Philip and Stiller, Christoph and Urtasun, Raquel},
  journal={The International Journal of Robotics Research},
  volume={32},
  number={11},
  pages={1231--1237},
  year={2013},
  publisher={SAGE Publications Sage UK: London, England}
}
@inproceedings{mo2025connecting,
  title={Connecting Joint-Embedding Predictive Architecture with Contrastive Self-supervised Learning},
  author={Mo, Shentong and Tong, Peter},
  booktitle={NeurIPS},
  year={2024}
}
@article{chen2020improved,
  title={Improved baselines with momentum contrastive learning},
  author={Chen, Xinlei and Fan, Haoqi and Girshick, Ross and He, Kaiming},
  journal={arXiv preprint arXiv:2003.04297},
  year={2020}
}
@inproceedings{
tao2024what,
title={What Does a Visual Formal Analysis of the World's 500 Most Famous Paintings Tell Us About Multimodal {LLM}s?},
author={Muzi Tao and Saining Xie},
booktitle={The Second Tiny Papers Track at ICLR 2024},
year={2024},
url={https://openreview.net/forum?id=dINMwL186O}
}

@article{shi2024eagle,
  title={Eagle: Exploring the design space for multimodal llms with mixture of encoders},
  author={Shi, Min and Liu, Fuxiao and Wang, Shihao and Liao, Shijia and Radhakrishnan, Subhashree and Huang, De-An and Yin, Hongxu and Sapra, Karan and Yacoob, Yaser and Shi, Humphrey and others},
  journal={arXiv preprint arXiv:2408.15998},
  year={2024}
}
@article{soomro2012ucf101,
  title={UCF101: A dataset of 101 human actions classes from videos in the wild},
  author={Soomro, Khurram and Zamir, Amir Roshan and Shah, Mubarak},
  journal={arXiv preprint arXiv:1212.0402},
  year={2012}
}
@article{xu2024altogether,
  title={Altogether: Image Captioning via Re-aligning Alt-text},
  author={Xu, Hu and Huang, Po-Yao and Tan, Xiaoqing Ellen and Yeh, Ching-Feng and Kahn, Jacob and Jou, Christine and Ghosh, Gargi and Levy, Omer and Zettlemoyer, Luke and Yih, Wen-tau and others},
  journal={arXiv preprint arXiv:2410.17251},
  year={2024}
}

@article{beyer2024paligemma,
  title={Paligemma: A versatile 3b vlm for transfer},
  author={Beyer, Lucas and Steiner, Andreas and Pinto, Andr{\'e} Susano and Kolesnikov, Alexander and Wang, Xiao and Salz, Daniel and Neumann, Maxim and Alabdulmohsin, Ibrahim and Tschannen, Michael and Bugliarello, Emanuele and others},
  journal={arXiv preprint arXiv:2407.07726},
  year={2024}
}
@article{tong2024metamorph,
  title={Metamorph: Multimodal understanding and generation via instruction tuning},
  author={Tong, Shengbang and Fan, David and Zhu, Jiachen and Xiong, Yunyang and Chen, Xinlei and Sinha, Koustuv and Rabbat, Michael and LeCun, Yann and Xie, Saining and Liu, Zhuang},
  journal={arXiv preprint arXiv:2412.14164},
  year={2024}
}
@article{wang2024information,
  title={An Information Criterion for Controlled Disentanglement of Multimodal Data},
  author={Wang, Chenyu and Gupta, Sharut and Zhang, Xinyi and Tonekaboni, Sana and Jegelka, Stefanie and Jaakkola, Tommi and Uhler, Caroline},
  journal={arXiv preprint arXiv:2410.23996},
  year={2024}
}
@inproceedings{srinivasan2021wit,
  title={Wit: Wikipedia-based image text dataset for multimodal multilingual machine learning},
  author={Srinivasan, Krishna and Raman, Karthik and Chen, Jiecao and Bendersky, Michael and Najork, Marc},
  booktitle={Proceedings of the 44th international ACM SIGIR conference on research and development in information retrieval},
  pages={2443--2449},
  year={2021}
}
@inproceedings{noroozi2016unsupervised,
  title={Unsupervised learning of visual representations by solving jigsaw puzzles},
  author={Noroozi, Mehdi and Favaro, Paolo},
  booktitle={ECCV},
  year={2016},
}
@inproceedings{zhang2016colorful,
  title={Colorful image colorization},
  author={Zhang, Richard and Isola, Phillip and Efros, Alexei A},
  booktitle={ECCV},
  year={2016},
}
@inproceedings{gidaris2018unsupervised,
  title={Unsupervised representation learning by predicting image rotations},
  author={Gidaris, Spyros and Singh, Praveer and Komodakis, Nikos},
  booktitle={ICLR},
  year={2018}
}
@inproceedings{caron2021emerging,
  title={Emerging properties in self-supervised vision transformers},
  author={Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J{\'e}gou, Herv{\'e} and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  booktitle={ICCV},
  year={2021}
}

@InProceedings{he2016resnet,
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
title = {Deep Residual Learning for Image Recognition},
booktitle = {CVPR},
year = {2016}
}
@article{xie2016resnext,
  title={Aggregated Residual Transformations for Deep Neural Networks},
  author={Saining Xie and Ross Girshick and Piotr Dollár and Zhuowen Tu and Kaiming He},
  journal={arXiv preprint arXiv:1611.05431},
  year={2016}
}
@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Toronto, ON, Canada}
}
@inproceedings{goyal2019scaling,
  title={Scaling and benchmarking self-supervised visual representation learning},
  author={Goyal, Priya and Mahajan, Dhruv and Gupta, Abhinav and Misra, Ishan},
  booktitle={ICCV},
  year={2019}
}
@article{thomee2016yfcc100m,
  title={Yfcc100m: The new data in multimedia research},
  author={Thomee, Bart and Shamma, David A and Friedland, Gerald and Elizalde, Benjamin and Ni, Karl and Poland, Douglas and Borth, Damian and Li, Li-Jia},
  journal={Communications of the ACM},
  volume={59},
  number={2},
  pages={64--73},
  year={2016},
  publisher={ACM New York, NY, USA}
}

@inproceedings{zhai2022scaling,
  title={Scaling vision transformers},
  author={Zhai, Xiaohua and Kolesnikov, Alexander and Houlsby, Neil and Beyer, Lucas},
  booktitle={CVPR},
  year={2022}
}
@article{allal2025smollm2,
  title={SmolLM2: When Smol Goes Big--Data-Centric Training of a Small Language Model},
  author={Allal, Loubna Ben and Lozhkov, Anton and Bakouch, Elie and Bl{\'a}zquez, Gabriel Mart{\'\i}n and Penedo, Guilherme and Tunstall, Lewis and Marafioti, Andr{\'e}s and Kydl{\'\i}{\v{c}}ek, Hynek and Lajar{\'\i}n, Agust{\'\i}n Piqueres and Srivastav, Vaibhav and others},
  journal={arXiv preprint arXiv:2502.02737},
  year={2025}
}
@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}
@inproceedings{dehghani2023scaling,
  title={Scaling vision transformers to 22 billion parameters},
  author={Dehghani, Mostafa and Djolonga, Josip and Mustafa, Basil and Padlewski, Piotr and Heek, Jonathan and Gilmer, Justin and Steiner, Andreas Peter and Caron, Mathilde and Geirhos, Robert and Alabdulmohsin, Ibrahim and others},
  booktitle={ICML},
  year={2023},
}
@inproceedings{grill2020bootstrap,
  title={Bootstrap your own latent-a new approach to self-supervised learning},
  author={Grill, Jean-Bastien and Strub, Florian and Altch{\'e}, Florent and Tallec, Corentin and Richemond, Pierre and Buchatskaya, Elena and Doersch, Carl and Avila Pires, Bernardo and Guo, Zhaohan and Gheshlaghi Azar, Mohammad and others},
  booktitle={NeurIPS},
  year={2020}
}
@inproceedings{chen2021exploring,
  title={Exploring simple siamese representation learning},
  author={Chen, Xinlei and He, Kaiming},
  booktitle={CVPR},
  year={2021}
}

@inproceedings{naeem2024silc,
  title={Silc: Improving vision language pretraining with self-distillation},
  author={Naeem, Muhammad Ferjad and Xian, Yongqin and Zhai, Xiaohua and Hoyer, Lukas and Van Gool, Luc and Tombari, Federico},
  booktitle={ECCV},
  year={2024},
}
@inproceedings{singh2023effectiveness,
  title={The effectiveness of MAE pre-pretraining for billion-scale pretraining},
  author={Singh, Mannat and Duval, Quentin and Alwala, Kalyan Vasudev and Fan, Haoqi and Aggarwal, Vaibhav and Adcock, Aaron and Joulin, Armand and Doll{\'a}r, Piotr and Feichtenhofer, Christoph and Girshick, Ross and others},
  booktitle={ICCV},
  year={2023}
}
@inproceedings{silberman2012indoor,
  title={Indoor segmentation and support inference from rgbd images},
  author={Silberman, Nathan and Hoiem, Derek and Kohli, Pushmeet and Fergus, Rob},
  booktitle={ECCV},
  year={2012},
}
@article{sun2024eva,
  title={Eva-clip-18b: Scaling clip to 18 billion parameters},
  author={Sun, Quan and Wang, Jinsheng and Yu, Qiying and Cui, Yufeng and Zhang, Fan and Zhang, Xiaosong and Wang, Xinlong},
  journal={arXiv preprint arXiv:2402.04252},
  year={2024}
}
@inproceedings{chen2024internvl,
  title={Internvl: Scaling up vision foundation models and aligning for generic visual-linguistic tasks},
  author={Chen, Zhe and Wu, Jiannan and Wang, Wenhai and Su, Weijie and Chen, Guo and Xing, Sen and Zhong, Muyan and Zhang, Qinglong and Zhu, Xizhou and Lu, Lewei and others},
  booktitle={CVPR},
  year={2024}
}


@misc{fu2023mme,
  title={MME: a comprehensive evaluation benchmark for multimodal large language models. CoRR abs/2306.13394 (2023)},
  author={Fu, Chaoyou and Chen, Peixian and Shen, Yunhang and Qin, Yulei and Zhang, Mengdan and Lin, Xu and Qiu, Zhenyu and Lin, Wei and Yang, Jinrui and Zheng, Xiawu and others},
  year={2023}
}
@inproceedings{bai2024sequential,
  title={Sequential modeling enables scalable learning for large vision models},
  author={Bai, Yutong and Geng, Xinyang and Mangalam, Karttikeya and Bar, Amir and Yuille, Alan L and Darrell, Trevor and Malik, Jitendra and Efros, Alexei A},
  booktitle={CVPR},
  year={2024}
}
@inproceedings{wei2021finetuned,
  title={Finetuned language models are zero-shot learners},
  author={Wei, Jason and Bosma, Maarten and Zhao, Vincent Y and Guu, Kelvin and Yu, Adams Wei and Lester, Brian and Du, Nan and Dai, Andrew M and Le, Quoc V},
  booktitle={ICLR},
  year={2022}
}

@inproceedings{
  bordes2022high,
  title={High Fidelity Visualization of What Your Self-Supervised Representation Knows About},
  author={Florian Bordes and Randall Balestriero and Pascal Vincent},
  booktitle={TMLR},
  year={2022}
}

@ARTICLE{Wadekar2024-bs,
  title         = "The evolution of multimodal model architectures",
  author        = "Wadekar, Shakti N and Chaurasia, Abhishek and Chadha, Aman
                   and Culurciello, Eugenio",
  journal       = "arXiv [cs.AI]",
  month         =  may,
  year          =  2024,
  url           = "http://arxiv.org/abs/2405.17927",
  archivePrefix = "arXiv",
  primaryClass  = "cs.AI",
  eprint        = "2405.17927"
}

@article{luo2024task,
  title={Task Vectors are Cross-Modal},
  author={Luo, Grace and Darrell, Trevor and Bar, Amir},
  journal={arXiv preprint arXiv:2410.22330},
  year={2024}
}
@article{wan2024locca,
  title={LocCa: Visual Pretraining with Location-aware Captioners},
  author={Wan, Bo and Tschannen, Michael and Xian, Yongqin and Pavetic, Filip and Alabdulmohsin, Ibrahim and Wang, Xiao and Pinto, Andr{\'e} Susano and Steiner, Andreas and Beyer, Lucas and Zhai, Xiaohua},
  journal={arXiv preprint arXiv:2403.19596},
  year={2024}
}
@inproceedings{fan2025scaling,
  title={Scaling language-free visual representation learning},
  author={Fan, David and Tong, Shengbang and Zhu, Jiachen and Sinha, Koustuv and Liu, Zhuang and Chen, Xinlei and Rabbat, Michael and Ballas, Nicolas and LeCun, Yann and Bar, Amir and others},
  booktitle={ICCV},
  year={2025}
}
@article{thasarathan2025universal,
  title={Universal Sparse Autoencoders: Interpretable Cross-Model Concept Alignment},
  author={Thasarathan, Harrish and Forsyth, Julian and Fel, Thomas and Kowal, Matthew and Derpanis, Konstantinos},
  journal={arXiv preprint arXiv:2502.03714},
  year={2025}
}
@article{ridnik2021imagenet,
  title={Imagenet-21k pretraining for the masses},
  author={Ridnik, Tal and Ben-Baruch, Emanuel and Noy, Asaf and Zelnik-Manor, Lihi},
  journal={arXiv preprint arXiv:2104.10972},
  year={2021}
}
@article{balestriero2023cookbook,
  title={A cookbook of self-supervised learning},
  author={Balestriero, Randall and Ibrahim, Mark and Sobal, Vlad and Morcos, Ari and Shekhar, Shashank and Goldstein, Tom and Bordes, Florian and Bardes, Adrien and Mialon, Gregoire and Tian, Yuandong and others},
  journal={arXiv preprint arXiv:2304.12210},
  year={2023}
}
@InProceedings{Pathak_2016_CVPR,
author = {Pathak, Deepak and Krahenbuhl, Philipp and Donahue, Jeff and Darrell, Trevor and Efros, Alexei A.},
title = {Context Encoders: Feature Learning by Inpainting},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2016}
}

@article{maninis2024tips,
  title={TIPS: Text-image pretraining with spatial awareness},
  author={Maninis, Kevis-Kokitsi and Chen, Kaifeng and Ghosh, Soham and Karpur, Arjun and Chen, Koert and Xia, Ye and Cao, Bingyi and Salz, Daniel and Han, Guangxing and Dlabal, Jan and others},
  journal={ICLR},
  year={2025}
}
@misc{dito,
      title={Epsilon-VAE: Denoising as Visual Decoding}, 
      author={Long Zhao and Sanghyun Woo and Ziyu Wan and Yandong Li and Han Zhang and Boqing Gong and Hartwig Adam and Xuhui Jia and Ting Liu},
      year={2025},
      eprint={2410.04081},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2410.04081}, 
}
@inproceedings{quantize-dino,
  title={Stabilize the Latent Space for Image Autoregressive Modeling: A Unified Perspective}, 
  author={Yongxin Zhu and Bocheng Li and Hang Zhang and Xin Li and Linli Xu and Lidong Bing},
  booktitle={NeurIPS},
  year={2024}
}
@misc{VFMTok,
      title={Vision Foundation Models as Effective Visual Tokenizers for Autoregressive Image Generation}, 
      author={Anlin Zheng and Xin Wen and Xuanyang Zhang and Chuofan Ma and Tiancai Wang and Gang Yu and Xiangyu Zhang and Xiaojuan Qi},
      year={2025},
      eprint={2507.08441},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
}

@inproceedings{scalingvae,
      title={Learnings from Scaling Visual Tokenizers for Reconstruction and Generation}, 
      author={Philippe Hansen-Estruch and David Yan and Ching-Yao Chung and Orr Zohar and Jialiang Wang and Tingbo Hou and Tao Xu and Sriram Vishwanath and Peter Vajda and Xinlei Chen},
      year={2025},
      booktitle={ICML},
}

@misc{robustok,
      title={Image Tokenizer Needs Post-Training}, 
      author={Kai Qiu and Xiang Li and Hao Chen and Jason Kuen and Xiaohao Xu and Jiuxiang Gu and Yinyi Luo and Bhiksha Raj and Zhe Lin and Marios Savvides},
      year={2025},
      eprint={2509.12474},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2509.12474}, 
}

@inproceedings{styleganxl,
  title={StyleGAN-XL: Scaling StyleGAN to Large Diverse Datasets}, 
  author={Axel Sauer and Katja Schwarz and Andreas Geiger},
  booktitle={SIGGRAPH},
  year={2022}
}
@article{ren2025beyond,
  title={Beyond next-token: Next-x prediction for autoregressive visual generation},
  author={Ren, Sucheng and Yu, Qihang and He, Ju and Shen, Xiaohui and Yuille, Alan and Chen, Liang-Chieh},
  journal={arXiv preprint arXiv:2502.20388},
  year={2025}
}

@inproceedings{rcg,
  title={Return of Unconditional Generation: A Self-supervised Representation Generation Method}, 
  author={Tianhong Li and Dina Katabi and Kaiming He},
  booktitle={NeurIPS},
  year={2024}
}
@inproceedings{vahdat2021score,
  title={Score-based generative modeling in latent space},
  author={Vahdat, Arash and Kreis, Karsten and Kautz, Jan},
  booktitle={NeurIPS},
  year={2021}
}

@article{song2025selective,
  title={Selective Underfitting in Diffusion Models},
  author={Song, Kiwhan and Kim, Jaeyeon and Chen, Sitan and Du, Yilun and Kakade, Sham and Sitzmann, Vincent},
  journal={arXiv preprint arXiv:2510.01378},
  year={2025}
}


@inproceedings{pope2021intrinsic,
  title={The intrinsic dimension of images and its impact on learning},
  author={Pope, Phillip and Zhu, Chen and Abdelkader, Ahmed and Goldblum, Micah and Goldstein, Tom},
  booktitle={ICLR},
  year={2021}
}

@article{xar,
  title={Beyond next-token: Next-x prediction for autoregressive visual generation},
  author={Ren, Sucheng and Yu, Qihang and He, Ju and Shen, Xiaohui and Yuille, Alan and Chen, Liang-Chieh},
  journal={arXiv preprint arXiv:2502.20388},
  year={2025}
}

@article{de2019hierarchical,
  title={Hierarchical autoregressive image models with auxiliary decoders},
  author={De Fauw, Jeffrey and Dieleman, Sander and Simonyan, Karen},
  journal={arXiv preprint arXiv:1903.04933},
  year={2019}
}

@misc{dieleman2025latents,
  author = {Dieleman, Sander},
  title = {Generative modelling in latent space},
  url = {https://sander.ai/2025/04/15/latents.html},
  year = {2025}
}